{"meta":{"title":"J.P.Liu's Blog","subtitle":"IT博客","description":"https://www.mathmach.com","author":"formath(https://www.mathmach.com)","url":"https://www.mathmach.com","root":"/"},"pages":[{"title":"","date":"2023-09-19T02:53:03.258Z","updated":"2023-09-19T02:53:03.258Z","comments":false,"path":"about/index.html","permalink":"https://www.mathmach.com/about/index.html","excerpt":"","text":"从事工作 毕业后一直从事搜索推荐广告方面的工作，负责过以下方面的工作，还算熟悉，欢迎沟通。 机器学习平台 基于PS的大规模离散机器学习系统（LR/FM/FFM/SVD） 分布式深度学习系统（千亿特征、支持秒级在线学习） 特征抽取系统 模型预估系统 机器学习应用 大规模CTR预估 大规模异构图Graph Embedding 相关性模型 自然语言理解 其他广告系统里常用的算法模型 搜索广告/推荐广告 触发策略（自然语言理解、向量召回、相关性模型、Bert、对比学习等） 模型预估（GBDT、LR、FFM、DNN等） 机制策略（smart bidding、ocpc等） 技术兴趣 除了本职工作外，对业界一些技术也比较感兴趣。 分布式系统 Yarn、Flink、Kubernetes等 以下开源项目Contributor TensorFlow DMLC(PS-Lite-CORE) Euler 编程 主要使用C++和Python，也经常用Java/Scala写些Spark/MR和业务代码。 生活爱好 足球、台球、乒乓球、看剧 联系 GitHub: https://github.com/formath WeChat: ForMath"},{"title":"Tags","date":"2019-07-19T09:43:31.000Z","updated":"2023-09-19T02:53:03.291Z","comments":true,"path":"tags/index.html","permalink":"https://www.mathmach.com/tags/index.html","excerpt":"","text":"","author":"formath"}],"posts":[{"title":"点击率预估中的特征交互方法","slug":"feature_interaction_in_ctr","date":"2024-01-02T07:39:35.000Z","updated":"2024-01-10T09:48:36.144Z","comments":true,"path":"166b866f/","permalink":"https://www.mathmach.com/166b866f/","excerpt":"","text":"背景 特征交互方法 笛卡尔积 FM FFM FNN PNN NFM DeepFM Deep Crossing DCN xDeepFM FiBiNET AutoInt Co-Action Unit 参考 背景 我从事广告算法多年了，经历过点击率模型从XGBoost、大规模离散逻辑回归、FFM到后来DNN的演进。2017年从FFM迁移DNN时，主要考察的是FNN、PNN、DeppFM、Wide&amp;Deep这类模型，特点是特征交互基本沿用了浅层模型的方法，区别是后接了MLP。此后，DNN在CTR领域站稳脚跟后，才开始真正的面向DNN，思考怎样进行特征交互建模，比如吸收了Attention等NLP领域的技术，这一阶段主要思考通用的特征交互方法。近几年，又开始面向某类特征，设计专用的特征交互方法，值得一提的是一系列用户序列建模的方法在工业界取得了非常大的收益。本文记录一下对前两个阶段的一些工作的理解，第三阶段以后单独开一篇。 特征交互方法 笛卡尔积 两个离散特征A、B做拼接成特征C，既C = A&amp;B，参数空间为，其中D为embedding size。DNN在搜广推早期应用时，有些言论说Deep侧不用加组合特征，由mlp隐式学习组合就行，其实效果上是站不住脚的。根据我的经验，在Deep侧加一些组合特征，提供一些人工先验知识，可以帮助模型学习的更好。但组合特征本身也存在问题，这才引出后面很多怎么在模型内部进行特征交叉的结构优化工作。 优点：记忆性强，能显著提升模型效果。 难点：特征量级大导致模型非常大，需要比较强的工程能力。特征稀疏，存在很多低频组合特征，容易过拟合。一般通过频次准入控制过拟合，但对不同类型的特征组合可能需要不同频次，不太好设定。 缺点：泛化性不好，训练中没有出现的特征组合，在预估时查不到。 FM 每个特征有单独的emb，两个特征的emb内积作为交叉。参数空间为。 优点：有一定泛化性，训练中没有出现的特征组合，在预估时也可以得到内积。 缺点：每个特征只有一个emb，与不同特征组合时可能需要不同的emb。比如A&amp;B = 男性&amp;20岁对美女视频点击率高，A&amp;B = 女性&amp;20岁对帅哥视频点击率高，那20岁这个特征就被互相拉扯，最终指向性不明确了。 FFM 针对FM缺点的优化方案，每个特征，对每个slot，有单独的emb，两个特征的计算内积时，取对应的slot emb。参数空间为。 在工业界，会把slot聚合成group，每个特征对每个group学习一个emb，也可以选择哪些group之间可以交叉。在降低参数量的同时还能提效果，参数空间为。 根据我的经验，效果真的强，同等特征条件下，我们最初上DNN时用的Wide&amp;Deep也就稍微好一点点，也有大厂用FFM&amp;Deep。 优点：解决了FM的缺点，效果更好。 缺点：group聚合设计、group间交叉关系，需要一些经验。 FNN 论文1出发点是DNN学习大规模离散特征的emb太复杂，所以基于预训练FM对每个特征学出一个w和一个v向量，FNN将所有特征的w和v拼接起来过dnn。论文的出发点在当时是存在的，当时并没有能够支持大规模离散特征的开源深度学习框架，只有某些大厂有自研能力，包括百度凤巢第一版DNN时，也是先学习的逻辑回归，然后把逻辑回归的w拼起来过dnn，后面才有的MIO-Framework、Abacus、AI-Box深度学习框架。从方案上看，FM训练时，w是用于reduce sum，v是用于内积，FNN把它们拼起来过mlp，虽然理论上mlp是万能逼近器，能逼近出reduce sum和内积的效果，期待在有个保底的基础上，然后找到一个比reduce sum和内积更好的方程。根据我的经验，w、v和后面的mlp，驴唇不对马嘴，mlp连学习到保底水平都达不到，最终效果还不如FM。 PNN 论文2算是对FM的一个扩展，两个向量内积后，后面接mlp，而不是直接reduce sum。除了内积，也可以使用外积或内外积同时使用。内积PNN相比于FNN，不同的是向量端到端训练，可以适应mlp，而不像FNN那样驴唇不对马嘴。内积和外积算是比较基础的交互方法了，在其他模型比如NLP里应用也比较广泛，可以作为最基础的特征交互方法。 NFM 论文12和PNN有点像，不同的是两个向量做哈达玛积，后面接mlp。有个AFM类似的工作，两个向量哈达玛积的基础上，再乘个attention，感觉有点多余。 DeepFM 论文3和Wide&amp;Deep差不多，叫FM&amp;Deep更合适，论文把Wide侧换成FM模型，并且FM侧的emb和Deep侧的emb是共享的。这个结构在工业界用的挺多，不过和论文有一些不同点，比如FM侧和Deep侧的emb不共享、FM侧用FFM。 Deep Crossing 7加了个Residual，没啥好说的。之前在ffm迁dnn时试过，没用。 DCN 4把所有特征的emb起来后，每层通过简单乘法进行特征交叉，层数越多交叉越高阶，后面又出了个v2版5。DCN是bit-wise交互，并且只用最高阶的输出作为MLP输入。我之前在ffm迁dnn时试过v1版，效果不如wide&amp;deep。 xDeepFM 6每个slot emb间做哈达玛积，再过一个全连接网络，然后累加起来，得到下一层某个slot的emb。每次计算下一层一个slot emb，相当于遍历了所有高阶组合，多个slot有一点multi-head的作用，每个slot关注不同层面的组合。最后把所有阶的emb pooling起来过mlp。与DCN不同，xDeepFM关注slot-wise的交互，并且每阶的交互都保留下来过MLP。 难点：nn参数和计算量有点大，不太清楚有哪些工业界落地。 FiBiNET 14内积和哈达玛积太简单，FiNiNET里它俩结合了一下，叫做Bi-Linear Interaction，如下图。 论文另一个主要贡献是引入了SENet，学习特征的权重，权重作用到原始emb后得到新emb。然后，在原始emb和新emb上分别使用Bi-Linear Interaction进行二阶交互，然后全拼起来过mlp。 SENet后来在粗排用的挺多的，用于淘汰一些没用的特征，提升模型速度。Bi-Linear Interaction的话不太了解哪些厂有落地。 FiNiNET的特征交互后太宽，FiNiNET++15对它进行了优化。 AutoInt 8每个slot得到emb后，对所有slot做multi-head attention，得到融合了交互信息的slot emb。和xDeepFM类似，都是slot-wise交互。xDeepFM像RNN一样，下一阶的交互要依赖更浅一阶的交互，如果AutoInt做多层multi-head attention，也能获得高阶交互。 难点：计算量有点大。学术界作品，不清楚工业界有没有落地。 Co-Action Unit 9阿里妈妈提出的，在两个离散特征A、B做交叉时，把A的emb拆分成mlp每层的参数，B的emb作为mlp输入，mlp的输出向量作为交叉结果。 参数空间为，其中Misplaced &T &gt; D &amp;&amp; T &lt;&lt; N_{B}，T为作为mlp参数的emb大小。 这个结构对两个特征不是对称的，需要一个做mlp参数，一个做mlp输入。论文中做User Action Sequence和Target Item交叉时，把Target Item作为mlp，User Action Sequence中的项做mlp输入，文中没有解释这种选择的原因以及反过来的效果。文章11推测，是由于Target Item被更多地共享了，所以要拓宽其参数空间，更好的包容来交叉的信息。 论文和作者解读10的出发点比较有说服力，但最终这个结构是否能够解决论文的出发点我还是比较疑惑。和FM对比的话，缺点是一样的，会不会是mlp比内积效果好导致的效果提升。为了解决这个缺点，当然也可以像FFM那样设计，参数空间变为，比FFM参数稍多一点。 13介绍了CAN落地的一些工程细节，可以参考。 参考 [1][Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction](http://arxiv.org/abs/1601.02376) [2][Product-based Neural Networks for User Response Prediction](http://arxiv.org/abs/1611.00144) [3][DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](http://arxiv.org/abs/1703.04247) [4][Deep &amp; Cross Network for Ad Click Predictions](https://arxiv.org/abs/1708.05123) [5][DCN V2: Improved Deep &amp; Cross Network and Practical Lessons for Web-scale Learning to Rank Systems](http://arxiv.org/abs/2008.13535) [6][xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems](http://arxiv.org/abs/1803.05170) [7][Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features](http://www.kdd.org/kdd2016/papers/files/adf0975-shanA.pdf) [8][AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks](http://arxiv.org/abs/1810.11921) [9][CAN: Feature Co-Action for Click-Through Rate Prediction](https://arxiv.org/abs/2011.05625) [10][想为特征交互走一条新的路](https://zhuanlan.zhihu.com/p/287898562) [11][特征交互新思路|阿里 Co-action Network论文解读](http://xtf615.com/2021/01/10/can/) [12][Neural Factorization Machines for Sparse Predictive Analytics](http://arxiv.org/abs/1708.05027) [13][如何在工业界优化点击率预估:（五）特征交叉建模](https://zhuanlan.zhihu.com/p/489284765) [14][FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction](http://arxiv.org/abs/1905.09433) [15][FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for CTR Prediction](http://arxiv.org/abs/2209.05016)","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"点击率预估","slug":"点击率预估","permalink":"https://www.mathmach.com/tags/%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0/"},{"name":"CTR","slug":"CTR","permalink":"https://www.mathmach.com/tags/CTR/"},{"name":"特征工程","slug":"特征工程","permalink":"https://www.mathmach.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"Feature-Engineering","slug":"Feature-Engineering","permalink":"https://www.mathmach.com/tags/Feature-Engineering/"}],"author":"formath"},{"title":"同步模式模型训练中存在的一个简单但普遍的问题","slug":"sync_problems","date":"2023-09-19T03:33:26.000Z","updated":"2024-01-10T08:50:51.587Z","comments":true,"path":"a6a552a7/","permalink":"https://www.mathmach.com/a6a552a7/","excerpt":"","text":"背景 问题描述 不完美的解决方案 完美的解决方案 背景 点击率预估模型训练，在早期阶段由于模型结构比较简单，稀疏Embedding占比非常大而稠密参数较少，因此异步训练存在的参数更新冲突和延迟问题并不严重，异步训练是普遍采用的方式。随着Attention等复杂结构在稠密网络部分的应用，稠密参数的影响力变大，异步训练带来的参数更新问题越来越严重，制约着模型训练效果，另外随着GPU的应用，同步训练的性能问题也有缓解，所以同步训练渐渐成为主流。 同步训练有两种方式，一种是基于Parameter Server的同步训练，一种是基于AllReduce方式的训练。以目前推荐系统领域依然重度使用的TensorFlow为例，第一种经常采用TensorFlow SyncReplicasOptimizer，第二种经常采用Horovod TensorFlow。但这两种方式都存在一个简单却多年无人去解决的问题，对于用户群体这么大的框架来说，有点匪夷所思。 问题描述 同步训练的逻辑如下： epoch = 0while epoch &lt; max_epoch: try: read batch_data from data_iterator: 1）前向计算； 2）后向计算获得梯度； 3）所有worker同步梯度； 4）参数更新； except OutOfRange: save_checkpoint epoch++ 第3步需要收集所有worker的梯度，这里会存在一个问题： 数据并行并不能保证每个worker的数据量一模一样，导致worker的batch_num = all_data_num / worker_num / batch_size可能稍有不同。在收集梯度时，可能有些worker上的数据已经消耗完，这样就永远无法集齐work_num个梯度，导致训练任务卡住。 这个问题在PS模式或AllReduce都存在： TensorFlow SyncReplicasOptimizer问题 Horovod TensorFlow AllReduce问题 不完美的解决方案 由于每个worker的batch_num都不一样，那就不用它了，用一个全局的max_step做停止条件。 具体的方式为： step = 0while step &lt; max_step: 1）前向计算； 2）后向计算获得梯度； 3）所有worker同步梯度； 4）参数更新； 5）step++; 6）每n_step保存checkpoint； 这种方式是业界比较常见的方式，但还是有几个问题： * 由于每个worker都运行相同的步数，但每个worker的数据量不一致，就会有少量的数据多训练或少训练了一定次数。 * max_step要提前算好，对于大数据集可能比较浪费时间，人工拍一个值的话又不准。 * 对于特征准入，只需要在第一轮进行判断，按轮次训练更优。 这里还有需要注意的几个点： 1）SyncReplicaOptimizer奇葩的同步机制设计问题： &gt; https://github.com/tensorflow/tensorflow/issues/11753 &gt; https://stackoverflow.com/questions/36762872/distributed-tensorflow-tf-train-syncreplicasoptimizer-seems-not-synchronized &gt; &gt; SyncReplicaOptimizer does not really care if the replicas_to_aggregate gradients come from the different workers or not. Even if other workers are waiting or not initialized, the chief starts training immediately. And if you print the global_steps you will see same global_steps for replicas_to_aggregate times. This means that the chief pushes enough gradients for tf.train.SyncReplicaOptimizer to average and apply the gradients. So, start the chief worker process only after starting all other workers. 原因是： &gt; https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/SyncReplicasOptimizer &gt; &gt; Only after all variables have been updated, increment the global step. &gt; Only after step 4, pushes global_step in the token_queue, once for each worker replica. The workers can now fetch the global step, use it to update its local_step variable and start the next batch. Please note that some workers can consume multiple minibatches, while some may not consume even one. This is because each worker fetches minibatches as long as a token exists. If one worker is stuck for some reason and does not consume a token, another worker can use it. 为了解决这个问题，不要用： hook = optimizer.make_session_run_hook(is_chief) 要用： hook = optimizer.make_session_run_hook(is_chief, num_tokens=0) 2）Exception in thread QueueRunnerThread-dummy_queue-sync_token_q_EnqueueMany &gt; https://github.com/tensorflow/tensorflow/issues/20833 因为每个worker的数据量不一致，在最后一个step的时候，有些worker已经结束了，但梯度收集器还在等待梯度入队列，等不到就会超时报异常。 为了解决这个问题，dataset不要只repeat N轮，需要设成无限，通过max_step进行停止。 不要用： tf.data.SomeDataset(...).repeat(epoch=N).batch(batch_size) 要用： tf.data.SomeDataset(...).repeat(epoch=-1).batch(batch_size) 3）根据样本量计算出来的max_step，实际运行的step数比这个少就退出了。 原因是丢弃了一些过时梯度。 &gt; https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train/SyncReplicasOptimizer &gt; &gt; In a typical asynchronous training environment, it's common to have some stale gradients. For example, with a N-replica asynchronous training, gradients will be applied to the variables N times independently. Depending on each replica's training speed, some gradients might be calculated from copies of the variable from several steps back (N-1 steps on average). This optimizer avoids stale gradients by collecting gradients from all replicas, averaging them, then applying them to the variables in one shot, after which replicas can fetch the new variables and continue. 解决方案：同2，给数据多留一些buffer。 完美的解决方案 在TensorFlow/DNN时代之前，为了训练大规模离散LR、FFM类模型，我在公司内部开发了一个基于PS的分布式训练框架，其支持BSP、ASP、SSP三种同步方式，其中的BSP训练方式当时也面临着同样问题。我的解法是： 当有worker已经读完一轮数据后，它向ps节点发送一个worker_done信号，ps侧每轮会从0开始累加这个信号，记为worker_done_num，每次进行梯度收集时，只收集worker_num - worker_done_num个梯度就进行参数更新，这样就能完美的保证每条数据都训练max_epoch次并且不会卡住。","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"DeepSpeed-Chat强化学习策略","slug":"deep_speed_chat_rlhf","date":"2023-07-10T13:56:45.000Z","updated":"2023-09-19T02:53:03.254Z","comments":true,"path":"be7f3b4f/","permalink":"https://www.mathmach.com/be7f3b4f/","excerpt":"","text":"背景 符号定义 Off-Policy Advantage Actor-Critic标准范式 DeepSpeed-Chat强化学习策略 Reward设计 Advantage设计 Actor Model Critic Model DeepSpeed-Chat强化学习训练逻辑 参考 背景 ChatGPT出现后，已经有许多开源项目尝试复现其效果，包括LLaMa、DeepSpeed-Chat、ColossalChat、ChatGLM等。其中DeepSpeed-Chat是微软Deep Speed团队的开源项目，其完整的提供了Supervised Fine-tuning、Reward Model Training、RLHF PPO Traing三阶段的代码，逻辑简单，模块划分清晰，另外也由于Deep Speed在大模型训练中的使用非常普遍，所以笔者近期正在研究DeepSpeed-Chat的代码。之前博客中已经介绍了全部三阶段的训练实战情况： DeepSpeed-Chat全流程训练实战 本文以DeepSpeed-Chat的实现为例，详细介绍下RLHF——基于人类反馈的强化学习策略，并与经典Off-Policy Actor-Critic策略做对比。 符号定义 ：样本量。：序列最大长度。：动作顺序，既预测第个时刻，属于。：时刻的状态，既当前已知的序列。：时刻做出的动作，既预测下一个。：做出动作的实际。：当前状态下未来能获得的期望平均收益，用于回归。：优势函数，表示在状态下选择特定的相比其他的优势值。：预估值，根据状态选择动作。：，模型预估值，表示当前状态下未来能获得的期望平均收益。：，模型预估值，表示当前状态下采取某行动后未来能获得的期望平均收益。：预估值，表示在状态下选择时获得的即时收益。：最新模型参数。：老的的模型参数。 Off-Policy Advantage Actor-Critic标准范式 Off-Policy策略，在老版本参数的模型下做出动作选择和环境交互，放入样本池，在后面训练过程中可以重复利用。样本格式可以为： 标准Advantage Actor-Critic强化学习中，的和Critic的是可训练模型。 其中Actor模型的Loss为： DeepSpeed-Chat强化学习策略 DeepSpeed-Chat和ColossalChat强化学习部分的策略借鉴了TRLX开源项目。从InstructGPT论文和一些开源复现中，可以推测出ChatGPT对于step和episode的定义。每次预估下一个token是一个step，完成一个完整response是一个episode。 Reward设计 每个episode获得一个收益，由Reward Model预估得到，Reward Model相当于强化学习中的环境。并且，所有step共享episode的reward。 Reward除了Reward Model预估值外，增加了当前Actor模型与SFT模型的KL散度，保证Actor模型不要改变的太远。因为Off-Policy理论中，采样模型和最新模型接近时才有效果保障，否则需要非常多的采样样本，因此这里增加KL保障是符合理论要求的。不过这里的KL计算逻辑和严格数学定义也不太一样。 def compute_rewards(self, prompts, log_probs, ref_log_probs, reward_score, action_mask): kl_divergence_estimate = -self.kl_ctl * (log_probs - ref_log_probs) rewards = kl_divergence_estimate start = prompts.shape[1] - 1 # 状态s_1在prompt最后一个token，动作a_1表示预测response的第一个token ends = start + action_mask[:, start:].sum(1) reward_clip = torch.clamp(reward_score, -self.clip_reward_value, self.clip_reward_value) batch_size = log_probs.shape[0] for j in range(batch_size): rewards[j, start:ends[j]][-1] += reward_clip[j] # 在最后一个token加reward_score return rewards Advantage设计 在标准的Advantage Actor-Critic策略中，。与此不同，ChatGPT的reward加在了最后一个token，因此每一步依赖下一步，可以看到计算adv时是从后向前遍历，reward从后向前传。 def get_advantages_and_returns(self, values, rewards, start): lastgaelam = 0 advantages_reversed = [] length = rewards.size()[-1] for t in reversed(range(start, length)): # 反向计算 nextvalues = values[:, t + 1] if t &lt; length - 1 else 0.0 delta = rewards[:, t] + self.gamma * nextvalues - values[:, t] lastgaelam = delta + self.gamma * self.lam * lastgaelam advantages_reversed.append(lastgaelam) advantages = torch.stack(advantages_reversed[::-1], dim=1) # 再反转 returns = advantages + values[:, start:] # adv(t) + value(t+1)更合理些 return advantages.detach(), returns Actor Model Actor模型以SFT模型初始化，其损失函数设计与标准Actor-Critic有个不同点，是PPO2策略，整体loss对原始PPO和PPO2进行了结合。 另外，代码中没有直接计算两个概率值相除，而是使用对数指数变换，应该是数值稳定性考虑。 def actor_loss_fn(self, logprobs, old_logprobs, advantages, mask): log_ratio = (logprobs - old_logprobs) * mask ratio = torch.exp(log_ratio) pg_loss1 = -advantages * ratio pg_loss2 = -advantages * torch.clamp(ratio, 1.0 - self.cliprange, 1.0 + self.cliprange) pg_loss = torch.sum(torch.max(pg_loss1, pg_loss2) * mask) / mask.sum() return pg_loss Critic Model Critic模型以Reward Model初始化，其损失函数为模型预估值与回报的差别，为平方损失的回归任务。这里比较奇怪的一点是为何如此设计，感觉更合理一些。 def critic_loss_fn(self, values, old_values, returns, mask): values_clipped = torch.clamp(values, old_values - self.cliprange_value, old_values + self.cliprange_value) vf_loss1 = (values - returns)**2 vf_loss2 = (values_clipped - returns)**2 vf_loss = 0.5 * torch.sum(torch.max(vf_loss1, vf_loss2) * mask) / mask.sum() return vf_loss DeepSpeed-Chat强化学习训练逻辑 训练逻辑是Off-Policy策略，外层循环读取prompt数据生成prompt+response数据放入样本池，内层循环从样本池中读取prompt+response数据进行Actor Model和Critic Model的训练。性能上，SFT模型放到CPU上，Actor模型通过DeepSpeed Hybrid Engine支持训练和推理两种模式的高效切换。 另外，Instruct论文中在Actor Loss中增加了一个SFT Loss和一个Unsupervised Loss，两个Loss也加到之前的Actor Loss上。 最终的Actor Loss为： 其中，SFT Loss部分保证和Actor模型和SFT模型偏离不远，Unsupervised Loss部分增加了一个自回归任务，整体Loss计算梯度做模型更新，而DeepSpeed-Chat只使用了Unsupervised，没有增加SFT部分（在reward计算时使用了，间接引入），并且先用Actor Loss更新，再用Unsupervised Loss更新。Actor模型参数都采用了Exponential Moving Averages策略。 def generate_experience(self, prompts, mask): self.eval() seq = self._generate_sequence(prompts, mask) # [batch_size, prompt_response_max_len] self.train() pad_token_id = self.tokenizer.pad_token_id attention_mask = seq.not_equal(pad_token_id).long() with torch.no_grad(): output = self.actor_model(seq, attention_mask=attention_mask) output_ref = self.ref_model(seq, attention_mask=attention_mask) reward_score = self.reward_model.forward_value(seq, attention_mask, prompt_length=self.prompt_length)['chosen_end_scores'].detach() values = self.critic_model.forward_value(seq, attention_mask, return_value_only=True).detach()[:, :-1] logits = output.logits logits_ref = output_ref.logits return { 'prompts': prompts, # [batch_size, prompt_max_len] 'logprobs': gather_log_probs(logits[:, :-1, :], seq[:, 1:]), # [batch_size, prompt_response_max_len] 'ref_logprobs': gather_log_probs(logits_ref[:, :-1, :], seq[:, 1:]), # [batch_size, prompt_response_max_len] 'value': values, # [batch_size, prompt_response_max_len] 'rewards': reward_score, # [batch_size, 1] 'input_ids': seq, # [batch_size, prompt_response_max_len] \"attention_mask\": attention_mask # [batch_size, prompt_response_max_len] }def train_rlhf(self, inputs): ### process the old outputs prompts = inputs['prompts'] log_probs = inputs['logprobs'] ref_log_probs = inputs['ref_logprobs'] reward_score = inputs['rewards'] values = inputs['value'] attention_mask = inputs['attention_mask'] seq = inputs['input_ids'] start = prompts.size()[-1] - 1 action_mask = attention_mask[:, 1:] old_values = values with torch.no_grad(): old_rewards = self.compute_rewards(prompts, log_probs, ref_log_probs, reward_score, action_mask) advantages, returns = self.get_advantages_and_returns(old_values, old_rewards, start) ### process the new outputs batch = {'input_ids': seq, \"attention_mask\": attention_mask} actor_prob = self.actor_model(**batch, use_cache=False).logits actor_log_prob = gather_log_probs(actor_prob[:, :-1, :], seq[:, 1:]) actor_loss = self.actor_loss_fn(actor_log_prob[:, start:], log_probs[:, start:], advantages, action_mask[:, start:]) self.actor_model.backward(actor_loss) self.actor_model.step() value = self.critic_model.forward_value(**batch, return_value_only=True, use_cache=False)[:, :-1] critic_loss = self.critic_loss_fn(value[:, start:], old_values[:, start:], returns, action_mask[:, start:]) self.critic_model.backward(critic_loss) self.critic_model.step() return actor_loss, critic_loss 参考 台大李宏毅强化学习课程 DeepSpeed-Chat ColossalChat TRLX Training language models to follow instructions with human feedback DeepSpeed-Chat全流程训练实战","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://www.mathmach.com/tags/ChatGPT/"},{"name":"DeepSpeed","slug":"DeepSpeed","permalink":"https://www.mathmach.com/tags/DeepSpeed/"},{"name":"DeepSpeed-Chat","slug":"DeepSpeed-Chat","permalink":"https://www.mathmach.com/tags/DeepSpeed-Chat/"},{"name":"RLHF","slug":"RLHF","permalink":"https://www.mathmach.com/tags/RLHF/"},{"name":"PPO","slug":"PPO","permalink":"https://www.mathmach.com/tags/PPO/"},{"name":"Actor-Critic","slug":"Actor-Critic","permalink":"https://www.mathmach.com/tags/Actor-Critic/"},{"name":"强化学习","slug":"强化学习","permalink":"https://www.mathmach.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"}],"author":"formath"},{"title":"DeepSpeed-Chat全流程训练实战","slug":"deep_speed_chat_in_action","date":"2023-07-07T03:58:27.000Z","updated":"2023-09-19T02:53:03.254Z","comments":true,"path":"ff7e0546/","permalink":"https://www.mathmach.com/ff7e0546/","excerpt":"","text":"背景 运行条件准备 运行环境 数据和模型 模型下载 数据下载 Step 1: SFT训练 tokenizer 训练数据读取 任务启动脚本 启动训练 Step 2: Reward Model训练 tokenizer 训练数据读取 任务启动脚本 启动训练 Step 3: RLHF训练 tokenizer 训练数据读取 任务启动脚本 启动训练 对话测试 参考 背景 ChatGPT出现后，已经有许多开源项目尝试复现其效果，包括LLaMa、DeepSpeed-Chat、ColossalChat、ChatGLM等。其中DeepSpeed-Chat是微软Deep Speed团队的开源项目，其完整的提供了Supervised Fine-tuning、Reward Model Training、RLHF PPO Traing三阶段的代码，逻辑简单，模块划分清晰，另外也由于Deep Speed在大模型训练中的使用非常普遍，所以笔者近期正在研究DeepSpeed-Chat的代码。本文介绍下在13b模型上运行SFT、RW、RLHF全部三阶段的实战情况。 运行条件准备 运行环境 OS: CentOS 7GPU: A100 80GCuda: 11.0Python: 3.9.6Conda: 4.10.3GCC: 7.3.1 安装依赖： pip install datasetspip install sentencepiecepip install protobufpip install acceleratepip install torch# pip最新版0.9.5有bug，所以用源码安装git clone https://github.com/microsoft/DeepSpeed.gitcd DeepSpeedpip install -e .# pip最新包可能不支持某些模型，所以用源码安装git clone https://github.com/huggingface/transformers.gitcd transformerspip install -e . 数据和模型 由于公司内GPU集群的机器不允许连接外网，因此先在本地将模型和数据准备好后再传到GPU机器。 参考文档：transformers offline mode。 开启VPN，按下面代码从Huggingface下载对应模型、词典和数据，完成后将model_output_dir和dataset_output_dir目录传到GPU机器。 模型下载 如果AutoModel.from_pretrained(model_name)内存不足，可以直接从下载缓存cache_dir/model_name/snapshot目录拉取模型。cache_dir的具体配置可以参考transformers cache。 下载大模型，用于训练SFT Model。 from transformers import AutoModel, AutoTokenizermodel_name = 'facebook/opt-13b' # change this to the model you needmodel_output_dir = 'your_dir/facebook_opt_13b'model = AutoModel.from_pretrained(model_name)model.save_pretrained(model_output_dir)tokenizer = AutoTokenizer.from_pretrained(model_name)tokenizer.save_pretrained(model_output_dir) 下载完成后，目录下包含了model和tokenizer的具体数据。 其中config.json为模型配置，内容为： { \"_name_or_path\": \"facebook/opt-13b\", \"_remove_final_layer_norm\": false, \"activation_dropout\": 0.0, \"activation_function\": \"relu\", \"architectures\": [ \"OPTForCausalLM\" ], \"attention_dropout\": 0.0, \"bos_token_id\": 2, \"do_layer_norm_before\": true, \"dropout\": 0.1, \"eos_token_id\": 2, \"ffn_dim\": 20480, \"hidden_size\": 5120, \"init_std\": 0.02, \"layerdrop\": 0.0, \"max_position_embeddings\": 2048, \"model_type\": \"opt\", \"num_attention_heads\": 40, \"num_hidden_layers\": 40, \"output_projection\": true, \"pad_token_id\": 1, \"prefix\": \"&lt;/s&gt;\", \"torch_dtype\": \"float16\", \"transformers_version\": \"4.21.0.dev0\", \"use_cache\": true, \"vocab_size\": 50272, \"word_embed_proj_dim\": 5120} 下载小规模模型，用于训练Reward Model。 from transformers import AutoModel, AutoTokenizermodel_name = 'facebook/opt-350m' # change this to the model you needmodel_output_dir = 'your_dir/facebook_opt_350m'model = AutoModel.from_pretrained(model_name)model.save_pretrained(model_output_dir)tokenizer = AutoTokenizer.from_pretrained(model_name)tokenizer.save_pretrained(model_output_dir) 数据下载 以Dahoas/rm-static数据为例，可自行下载其他数据。 import datasetsdataset_name = 'Dahoas/rm-static' # change this to the dataset you needdataset_output_dir = 'your_dir/dahoas_rm_static'dataset = datasets.load_dataset(dataset_name)dataset.save_to_disk(dataset_output_dir) Step 1: SFT训练 tokenizer 因为不能联网，所以改成强制使用本地文件，修改以下代码。 DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/utils.py： def load_hf_tokenizer(model_name_or_path, fast_tokenizer=True): #if os.path.exists(model_name_or_path): # # Locally tokenizer loading has some issue, so we need to force download # model_json = os.path.join(model_name_or_path, \"config.json\") # if os.path.exists(model_json): # model_json_file = json.load(open(model_json)) # model_name = model_json_file[\"_name_or_path\"] # tokenizer = AutoTokenizer.from_pretrained(model_name, # fast_tokenizer=True) #else: tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, fast_tokenizer=True) return tokenizer DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py： #tokenizer = load_hf_tokenizer(args.model_name_or_path, fast_tokenizer=True)tokenizer = load_hf_tokenizer('your_dir/facebook_opt_13b', fast_tokenizer=True) 训练数据读取 训练数据也使用缓存，修改文件DeepSpeedExamples/applications/DeepSpeed-Chat/training/utils/data/raw_datasets.py： class PromptRawDataset(object): def __init__(self, output_path, seed, local_rank, dataset_name): self.output_path = output_path self.seed = seed self.local_rank = local_rank if not dataset_name == 'local/jsonfile': #self.raw_datasets = load_dataset(dataset_name) # 即使dataset_name是本地目录，也会先联网，可以设置export HF_DATASETS_OFFLINE=1或换用load_from_disk self.raw_datasets = datasets.load_from_disk(dataset_name) 任务启动脚本 修改文件DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/single_node/run_13b.sh： deepspeed main.py \\ --data_path your_dir/dahoas_rm_static \\ --data_split 2,4,4 \\ --model_name_or_path your_dir/facebook_opt_13b \\ --per_device_train_batch_size 4 \\ --per_device_eval_batch_size 4 \\ --max_seq_len 512 \\ --learning_rate 1e-4 \\ --weight_decay 0. \\ --num_train_epochs 16 \\ --gradient_accumulation_steps 1 \\ --lr_scheduler_type cosine \\ --num_warmup_steps 0 \\ --seed 1234 \\ --gradient_checkpointing \\ --zero_stage $ZERO_STAGE \\ --lora_dim 128 \\ --lora_module_name decoder.layers. \\ --deepspeed \\ --output_dir $OUTPUT \\ &amp;&gt; $OUTPUT/training.log 启动训练 cd DeepSpeedExamples/applications/DeepSpeed-Chatpython train.py --step 1 --actor-model 13b --deployment-type single_node 没问题的话就可以在DeepSpeed-Chat/output/actor-models/13b/training.log看到训练情况了： 229 ***** Running training *****230 ***** Evaluating perplexity, Epoch 0/16 *****231 ppl: 2771.550537109375232 Beginning of Epoch 1/16, Total Micro Batches 3813233 [2023-07-07 15:34:07,295] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1234 Invalidate trace cache @ step 0: expected module 13, but got module 0235 [2023-07-07 15:34:08,960] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768236 [2023-07-07 15:34:10,421] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384237 [2023-07-07 15:34:12,200] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192238 [2023-07-07 15:34:13,468] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096239 [2023-07-07 15:34:14,738] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048240 [2023-07-07 15:34:17,337] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, reducing to 1024241 [2023-07-07 15:34:19,964] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=7, lr=[9.999999940336507e-05, 9.999999940336507e-05], mom=[(0.9, 0.95), (0.9, 0.95)]242 [2023-07-07 15:34:19,964] [INFO] [timer.py:199:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=2.9106454245373556, CurrSamplesPerSec=3.07555254100577, MemAllocat ed=36.12GB, MaxMemAllocated=40.26GB243 [2023-07-07 15:34:32,952] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=7, lr=[9.999998879652199e-05, 9.999998879652199e-05], mom=[(0.9, 0.95), (0.9, 0.95)]244 [2023-07-07 15:34:32,952] [INFO] [timer.py:199:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=3.003776798900565, CurrSamplesPerSec=3.0893153637186064, MemAlloca ted=36.12GB, MaxMemAllocated=40.26GB245 [2023-07-07 15:34:45,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=7, lr=[9.99999649311278e-05, 9.99999649311278e-05], mom=[(0.9, 0.95), (0.9, 0.95)]246 [2023-07-07 15:34:45,914] [INFO] [timer.py:199:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=3.0336418997022405, CurrSamplesPerSec=3.0865395529882864, MemAlloc ated=36.12GB, MaxMemAllocated=40.26GB247 [2023-07-07 15:34:58,905] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=7, lr=[9.999992780718883e-05, 9.999992780718883e-05], mom=[(0.9, 0.95), (0.9, 0.95)]248 [2023-07-07 15:34:58,906] [INFO] [timer.py:199:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=3.0462048161750825, CurrSamplesPerSec=3.0772742271467597, MemAlloc ated=36.12GB, MaxMemAllocated=40.26GB249 [2023-07-07 15:35:11,897] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=7, lr=[9.999987742471495e-05, 9.999987742471495e-05], mom=[(0.9, 0.95), (0.9, 0.95)]250 [2023-07-07 15:35:11,898] [INFO] [timer.py:199:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=3.0535265510887886, CurrSamplesPerSec=3.0858537581286103, MemAlloc ated=36.12GB, MaxMemAllocated=40.26GB251 [2023-07-07 15:35:24,885] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=7, lr=[9.999981378371948e-05, 9.999981378371948e-05], mom=[(0.9, 0.95), (0.9, 0.95)]252 [2023-07-07 15:35:24,886] [INFO] [timer.py:199:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=3.058528008594015, CurrSamplesPerSec=3.089157229026472, MemAllocat ed=36.12GB, MaxMemAllocated=40.26GB253 [2023-07-07 15:35:37,859] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=7, lr=[9.999973688421931e-05, 9.999973688421931e-05], mom=[(0.9, 0.95), (0.9, 0.95)]254 [2023-07-07 15:35:37,860] [INFO] [timer.py:199:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=3.062547383419453, CurrSamplesPerSec=3.0862085394366274, MemAlloca ted=36.12GB, MaxMemAllocated=40.26GB255 [2023-07-07 15:35:50,853] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=7, lr=[9.999964672623485e-05, 9.999964672623485e-05], mom=[(0.9, 0.95), (0.9, 0.95)]256 [2023-07-07 15:35:50,854] [INFO] [timer.py:199:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=3.0649199847585775, CurrSamplesPerSec=3.081825198818058, MemAlloca ted=36.12GB, MaxMemAllocated=40.26GB 每轮评估指标的变化情况如下，可以看到开始几轮效果反而下降，后面几轮又开始提升。 ppl: 2771.550537109375ppl: 2.4410853385925293ppl: 2.680394172668457ppl: 2.779381036758423ppl: 2.80298113822937ppl: 2.813119888305664ppl: 2.8290116786956787ppl: 2.833710193634033ppl: 2.832332134246826ppl: 2.8273046016693115ppl: 2.8215107917785645ppl: 2.8162872791290283ppl: 2.808527946472168ppl: 2.792924165725708ppl: 2.775484561920166ppl: 2.755317449569702ppl: 2.74511981010437 大概1小时24分钟训练一轮，GPU存储占用47G，其中模型参数占用24G。 根据ChatGPT量化分析（二） - 存储占用分析，中间激活存储占用： 代入参数，可得中间激活占用19G。如果全量微调中间激活的梯度也占用19G，但这里使用了Lora，可训练参数较少，并且开启了ZeRO-Offload，将优化器状态存储放到了CPU。忽略掉这些参数的话，模型参数24G加上中间激活19G共43G，与实际的47G差距不大，符合预期。 Step 2: Reward Model训练 tokenizer DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/main.py： #tokenizer = load_hf_tokenizer(args.model_name_or_path, fast_tokenizer=True)tokenizer = load_hf_tokenizer('your_dir/facebook_opt_350m', fast_tokenizer=True) 训练数据读取 训练数据与SFT阶段一样，所以这里没有修改。 任务启动脚本 修改文件DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/single_node/run_350m.sh： deepspeed main.py \\ --data_path your_dir/dahoas_rm_static \\ --data_split 2,4,4 \\ --model_name_or_path your_dir/facebook_opt_350m \\ --num_padding_at_beginning 1 \\ --per_device_train_batch_size 4 \\ --per_device_eval_batch_size 4 \\ --max_seq_len 512 \\ --learning_rate 5e-5 \\ --weight_decay 0.1 \\ --num_train_epochs 1 \\ --disable_dropout \\ --gradient_accumulation_steps 1 \\ --lr_scheduler_type cosine \\ --num_warmup_steps 0 \\ --seed 1234 \\ --zero_stage $ZERO_STAGE \\ --deepspeed \\ --output_dir $OUTPUT \\ &amp;&gt; $OUTPUT/training.log 启动训练 cd DeepSpeedExamples/applications/DeepSpeed-Chatpython train.py --step 2 --reward-model 350m --deployment-type single_node 没问题的话就可以在DeepSpeed-Chat/output/reward-models/350m/training.log看到训练情况了。每轮评估指标的变化情况： chosen_last_scores (higher is better) : 2.7135448455810547, acc (higher is better) : 0.4949999749660492chosen_last_scores (higher is better) : -8.86074161529541, acc (higher is better) : 0.5600000023841858 GPU占用1.2G。 Step 3: RLHF训练 tokenizer DeepSpeed-Chat代码里actor和critic模型用的是同一个tokenizer，因为opt-13b和opt-350m的词典一样所以只加载一个tokenizer不会报错，如果不一致的话需要修改代码，让它们用各自的tokenizer。 训练数据读取 训练数据与SFT、RW阶段一样，所以这里没有修改。 任务启动脚本 目前DeepSpeed Hybrid Engine会报以下错，所以先关掉--enable_hybrid_engine。关掉后则会CUDA out of memory，所以再加上--offload_reference_model。 232 File \"/home/formath/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/rlhf_engine.py\", line 119, in _init_actor233 actor_engine, *_ = deepspeed.initialize(model=actor_model,234 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/__init__.py\", line 153, in initialize235 engine = DeepSpeedHybridEngine(args=args,236 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 52, in __init__237 self.create_inference_module()238 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 359, in create_inference_module239 self.create_inference_containers(self.module)240 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 308, in create_inference_containers241 self.create_inference_containers(child, layer_id=layer_id)242 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 308, in create_inference_containers243 self.create_inference_containers(child, layer_id=layer_id)244 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 308, in create_inference_containers245 self.create_inference_containers(child, layer_id=layer_id)246 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 288, in create_inference_containers247 self._inference_containers.append(self.inference_policies[child.__class__][0](248 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/hybrid_engine.py\", line 107, in new_inference_container249 _container.set_tensor_parallel_config(self._config.hybrid_engine.inference_tp_size, self.mp_group)250 File \"/conda/envs/py39/lib/python3.9/site-packages/deepspeed/runtime/engine.py\", line 460, in __getattr__251 raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")252 AttributeError: 'DeepSpeedHybridEngine' object has no attribute 'mp_group' 修改文件DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/single_node/run_13b.sh： deepspeed --master_port 12346 main.py \\ --data_path your_dir/dahoas_rm_static \\ --data_split 2,4,4 \\ --actor_model_name_or_path $ACTOR_MODEL_PATH \\ --critic_model_name_or_path $CRITIC_MODEL_PATH \\ --num_padding_at_beginning 1 \\ --per_device_train_batch_size 16 \\ --per_device_mini_train_batch_size 16 \\ --generation_batch_numbers 1 \\ --ppo_epochs 1 \\ --max_answer_seq_len 256 \\ --max_prompt_seq_len 256 \\ --actor_learning_rate ${Actor_Lr} \\ --critic_learning_rate ${Critic_Lr} \\ --num_train_epochs 1 \\ --lr_scheduler_type cosine \\ --gradient_accumulation_steps 1 \\ --num_warmup_steps 100 \\ --deepspeed --seed 1234 \\ --offload_reference_model \\ --inference_tp_size 2 \\ --actor_zero_stage $ACTOR_ZERO_STAGE \\ --critic_zero_stage $CRITIC_ZERO_STAGE \\ --actor_gradient_checkpointing \\ --disable_actor_dropout \\ --actor_lora_dim 128 \\ --actor_lora_module_name decoder.layers. \\ --output_dir $OUTPUT \\ &amp;&gt; $OUTPUT/training.log 启动训练 cd DeepSpeedExamples/applications/DeepSpeed-Chatpython train.py --step 3 --actor-model 13b --reward-model 350m --deployment-type single_node 没问题的话就可以在DeepSpeed-Chat/step3-models/13b/training.log看到训练情况了。 723 ***** Running training *****724 Beginning of Epoch 1/1, Total Generation Batches 1907725 [2023-07-12 14:56:26,391] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1726 [2023-07-12 14:56:26,872] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1727 epoch: 0|step: 0|ppo_ep: 1|act_loss: -0.341552734375|cri_loss: 0.1712646484375|unsuper_loss: 0.0728 average reward score: -7.6640625729 -------------------------------------------------------------------------------------730 [2023-07-12 14:57:59,326] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768731 [2023-07-12 14:58:00,227] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768732 epoch: 0|step: 1|ppo_ep: 1|act_loss: -0.386474609375|cri_loss: 0.19775390625|unsuper_loss: 0.0733 average reward score: -7.78125734 -------------------------------------------------------------------------------------735 [2023-07-12 14:59:19,445] [WARNING] [stage3.py:1898:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to pe rformance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelera tor().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time736 [2023-07-12 14:59:19,709] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384737 epoch: 0|step: 2|ppo_ep: 1|act_loss: -0.35400390625|cri_loss: 0.1790771484375|unsuper_loss: 0.0738 average reward score: -7.640625739 -------------------------------------------------------------------------------------740 [2023-07-12 15:00:39,293] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192741 epoch: 0|step: 3|ppo_ep: 1|act_loss: -0.31884765625|cri_loss: 0.1573486328125|unsuper_loss: 0.0742 average reward score: -7.61328125743 -------------------------------------------------------------------------------------744 [2023-07-12 15:01:58,839] [WARNING] [stage3.py:1898:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to pe rformance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelera tor().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time745 epoch: 0|step: 4|ppo_ep: 1|act_loss: -0.36962890625|cri_loss: 0.18896484375|unsuper_loss: 0.0746 average reward score: -7.78125747 -------------------------------------------------------------------------------------748 epoch: 0|step: 5|ppo_ep: 1|act_loss: -0.32373046875|cri_loss: 0.1724853515625|unsuper_loss: 0.0749 average reward score: -7.7109375750 -------------------------------------------------------------------------------------751 epoch: 0|step: 6|ppo_ep: 1|act_loss: -0.327392578125|cri_loss: 0.415283203125|unsuper_loss: 0.0752 average reward score: -8.3125753 -------------------------------------------------------------------------------------754 epoch: 0|step: 7|ppo_ep: 1|act_loss: -0.368408203125|cri_loss: 0.208740234375|unsuper_loss: 0.0755 average reward score: -7.84765625756 -------------------------------------------------------------------------------------757 epoch: 0|step: 8|ppo_ep: 1|act_loss: -0.340087890625|cri_loss: 0.1898193359375|unsuper_loss: 0.0758 average reward score: -7.76953125759 ------------------------------------------------------------------------------------- GPU内存占用77G，已经接近单卡极限，但利用率只有18%。 对话测试 以上训练结束后，就可以导入各阶段的模型进行对话了，比如用step 3保存的模型进行对话。 cd DeepSpeedExamples/applications/DeepSpeed-Chatpython chat.py --path /home/formath/DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/13b/actor --max_new_tokens 512 参考 DeepSpeed-Chat ColossalChat ChatGPT量化分析（二） - 存储占用分析 ZeRO-Offload","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://www.mathmach.com/tags/ChatGPT/"},{"name":"DeepSpeed","slug":"DeepSpeed","permalink":"https://www.mathmach.com/tags/DeepSpeed/"},{"name":"DeepSpeed-Chat","slug":"DeepSpeed-Chat","permalink":"https://www.mathmach.com/tags/DeepSpeed-Chat/"}],"author":"formath"},{"title":"模型召回如何打压热门内容","slug":"hot_item_suppress","date":"2023-06-30T02:13:37.000Z","updated":"2024-01-10T06:04:49.482Z","comments":true,"path":"a4afa06d/","permalink":"https://www.mathmach.com/a4afa06d/","excerpt":"","text":"背景 热门item的定义 热门item打压 数据角度 通过正样本打压 通过负样本打压 模型角度 特征角度 业务角度 参考资料 背景 理论上的召回模型，是根据概率分，从全部候选item中选出分数最高的top K个item作为召回结果。 其中，是模型参数，是为了概率归一化。 这里的根据业务目标不同可以调整，搜索场景可以是query和item的相关性，推荐场景可以是用户历史或实时偏好和item的相关性，广告场景可以是用户和item的eCPM，当然也可以建模多目标，比如同时考虑相关性和eCPM。 概率分和是正相关关系，所以只用根据打分选出top K即可。线上召回时由于耗时原因不可能遍历全部候选item计算，因此往往是双塔模型，既，是或内积等度量，候选item的向量可以离线计算好，线上user的向量实时生成，借助Faiss等向量检索工具进行高效的top K近似检索。 离线训练时，正样本往往是用户历史正反馈数据，比如点击、转化、收藏、转发。而难以计算，因此采用Noise Contrastive Estimation（NCE）、Negative Sampling（NEG）、Sampled Softmax（SSM）等方法近似估计，这些方法都使用了负采样。大规模Softmax近似估计方法在之前的几篇博客中已经介绍，可以参考： Noise Contrastive Estimation - 理论篇 Sampled Softmax - 理论篇 Softmax近似方法之NCE、NEG、Sampled Softmax对比 为了离线训练时的样本空间尽量和线上对齐，负采样要保证覆盖到全部item。另外，正样本中热门item的占比往往非常大，为了降低整体训练loss，最终得到的用户向量和热门item的向量往往分数更高，这样就导致线上召回时top K也被热门item占领，和业务目标偏离。 热门item的定义 用户喜欢的item作为可召回空间，又可分为热门的大众偏好和非热门的个性化偏好，所以热门和个性化是互斥的两个空间。在召回建模中，建模目标是喜欢与否。如背景介绍中描述，如果不进行热门item打压，可召回空间往往被大众偏好所占领，导致个性化空间不足，因此热门item打压的目标是在大众偏好和个性化偏好中寻找平衡。 那么，平衡又怎么定义好坏呢？在不打压热门item的时候，热门item占比80%，个性化item只占20%。打压之后，让热门item占比20%，个性化item占比80%算好吗，甚至个性化占100%可行吗？笔者认为可以。原因是召回往往是多通路召回，模型召回只是其中一路。热门item通过简单的统计即可实现召回，无需借助模型，并且辅助用户标签就可从热门item中过滤出用户喜欢的。因此，大众偏好这部分通过简单的召回策略即可实现，而复杂的模型召回可以更关注个性化偏好这部分。 当然，业务场景间差别非常大，笔者的观点在一些场景可能并不适用，仅供参考。 热门item打压 数据角度 通过正样本打压 正样本往往是用户历史正反馈数据，比如点击、转化、收藏、转发，这种样本生成方法自带偏向热门属性，因此直觉的办法就是降低正样本中的热门item样本的比例。但是，正样本又是稀缺的，降低热门item样本量的方法一定程度上损害了数据多样性，需要谨慎使用。 通过负样本打压 可以根据热度做负采样，热度越高被采中概率越大，这样就可以一定程度上对冲掉正样本中的热门item，在一些情况下热门item可能负采样太多导致打压过度（如背景所述笔者认为在多通路召回下问题不大）。比如，可以根据item的点击次数做负采样。 其中为负采样概率，为平衡负采样集中度和打压力度的配置。当时为均匀采样，覆盖广度最高但无负样本打压作用，当时覆盖广度降低同时负样本打压力度最强。 模型角度 如果采用NEG或SSM方法，在打分公式中引入了负样本概率消偏，新的打分公式为： 考虑概率值和热门程度正相关的情况下，由于，item越冷门，采样概率越小，分数补偿的越多，相当于变相打压了热门item。 注意这里只是在训练时打压了热门item，理论上只在离线训练时采用，线上检索时仍然使用未修正的打分，那么： 用未修正的打分公式检索时，效果正好相反，item越冷门，采样概率越小，分数补偿的越小，相当于变现提权了热门item。这里考虑到在训练时已经补偿了，所以检索时少补偿一点也是合理的，但是会不会又把训练时引入的热门打压在检索时消去掉了。如果有这种现象，可以在检索阶段继续打压。 检索阶段继续打压的方法很简单：线上用新打分公式。笔者认为可以尝试，它可以在检索时打压热门item，并且也不一定要与离线时使用的一致，可以在线实时调控。 如果线上向量检索时用新的打分公式，怎样将融入中呢？如果是内积，可以用，如果是，emb先归一化再concat，都只需要在向量中增加一列即可。 如果使用NEG方法，它忽略了负采样概率修正项，因此在训练和检索阶段都没有改变热门item问题，需要在其他层面解决。 特征角度 可以观察高分热门item是由哪些特征导致分数高，这样就可以将这些特征替换成非热门item的特征，实现分数打压。不过模型很黑盒，并且特征是异构的、离散的、数量又非常多，定位和替换特征有难度，不一定有可行性。另外强制替换特征会改变打分分布，导致模型评估指标和离线不一致，所以这种方法不太建议使用。 业务角度 从召回本身来看，往往是多通路召回，有些通路关注热门，有些通路关注个性化，这里要避免的就是所有通路都偏向热门。通路间有quota分配，可以人工干预热门通路的占比，甚至根据大盘业务指标实时自动调配。 从整个业务层面来看，召回只是最上游，下游还有粗排精排甚至重排，在排序环节也需要考虑多样性问题，另外也需要有item粒度实时提权或打压的运营干预手段。 参考资料 Noise Contrastive Estimation - 理论篇 Sampled Softmax - 理论篇 Softmax近似方法之NCE、NEG、Sampled Softmax对比 推荐系统传统召回是怎么实现热门item的打压?","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://www.mathmach.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"name":"推荐系统","slug":"推荐系统","permalink":"https://www.mathmach.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"计算广告","slug":"计算广告","permalink":"https://www.mathmach.com/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/"}],"author":"formath"},{"title":"ChatGPT量化分析（三） - 计算量分析","slug":"transformer_quant_analysis_third","date":"2023-06-05T09:40:15.000Z","updated":"2023-09-19T02:53:03.257Z","comments":true,"path":"b3deb998/","permalink":"https://www.mathmach.com/b3deb998/","excerpt":"","text":"背景 计算量分析 变量定义 Embedding Transformer Blocks Multi-head Attention MLP Add&amp;Norm Transformer Blocks计算量 推理阶段 训练阶段 参考资料 背景 ChatGPT出现后，惊人的效果完全颠覆了业界人员包括笔者的认知，抛开其模型细节层面的因素，已公开的训练方法，需要巨量的数据和计算资源，门槛非常高。本文基于公开资料，希望以量化方式分多篇介绍ChatGPT的分析结论，具体内容包含以下三篇，本文为计算量分析篇。 ChatGPT量化分析（一） - 模型参数分析 ChatGPT量化分析（二） - 存储占用分析 ChatGPT量化分析（三） - 计算量分析 ChatGPT模型结构为Transformer，下面对计算细节拆解分析。 计算量分析 变量定义 模型参数数量浮点运算次数，用来表示计算量 Embedding embedding层是lookup操作，输入是词序列，输出是词序列embedding，浮点操作可忽略。 Transformer Blocks transformer block的计算图如下，每个transformer block主要包含四部分，既multi-head attention和mlp，以及两个add&amp;norm。 Multi-head Attention multi-head attention结构如图： 变量定义： 样本样本的序列长度数量、矩阵的维度矩阵的维度和往往一样，都表示为数量数量 multi-head attention的计算逻辑为： 其中，。 矩阵乘法算子中包括浮点乘法和加法，的输入激活Tensor是，在第一个block是词本身embedding和position embedding之和，在其他block是上游block的输出，的形状为，的形状为，因此计算量为，和同； Softmax算子的输入Tensor为和，形状为，和相乘的计算量为，操作的计算量为，操作计算量为，归一化操作计算量为，共； 的输入Tensor为和，计算量为； 每个head的存计算量为，共个head，存储占用为：； 输入为激活和参数，计算量为。 综上，multi-head attention的总计算量为： MLP multi-head attention后面，接两层的全连接网络，计算逻辑为： 其中，。 矩阵乘法算子的输入激活Tensor 是multi-head attention输出，形状为，形状为，计算量为； 加法部分输入是激活和参数，计算量为； 输入和输出都是，计算量简单计为； 的输入是激活和参数，计算量为； 加法部分输入是激活和参数，计算量为； 综上，mlp部分的总计算量为： Add&amp;Norm 两个add部分的计算量为。每个norm中均值计算量为，标准差计算量为，归一化计算量为 所以，add&amp;norm部分的存储占用为： Transformer Blocks计算量 综上，每个transformer block计算计算量为： 共个transformer block，总计算量为： 推理阶段 在推理阶段，计费量为： 按GPT3 175B配置计算： 按的话，约为。每个token每个参数的计算量为： 每个token的计算量约为。 训练阶段 在训练阶段，需要反向传播，反向传播计算量和前向一致。另外还有梯度更新，Adam需要更新两个累积值和参数，计算量简单计为，因此训练的计算量为： 按GPT3 175B配置计算： 按GPT3 174B配置和计算，训练的总计算量为，与GPT3论文非常接近。在300张A100 80G卡集群训练，GPU利用率40%情况下，需要耗时。每个token每个参数的计算量为： 每个token的计算量约为。 参考资料 Attention Is All You Need Language Models are Few-Shot Learners 分析transformer模型的参数量、计算量、中间激活、KV cache","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"ChatGPT量化分析（二） - 存储占用分析","slug":"transformer_quant_analysis_second","date":"2023-06-01T02:32:41.000Z","updated":"2023-09-19T02:53:03.257Z","comments":true,"path":"4e7f3af5/","permalink":"https://www.mathmach.com/4e7f3af5/","excerpt":"","text":"背景 模型参数 训练阶段 推理阶段 中间激活 Embedding Transformer Blocks Multi-head Attention MLP Add&amp;Norm 中间激活存储占用 训练阶段 推理阶段 参考资料 背景 ChatGPT出现后，惊人的效果完全颠覆了业界人员包括笔者的认知，抛开其模型细节层面的因素，已公开的训练方法，需要巨量的数据和计算资源，门槛非常高。本文基于公开资料，希望以量化方式分多篇介绍ChatGPT的分析结论，具体内容包含以下三篇，本文为存储占用分析篇。 ChatGPT量化分析（一） - 模型参数分析 ChatGPT量化分析（二） - 存储占用分析 ChatGPT量化分析（三） - 计算量分析 ChatGPT模型结构为Transformer，Transformer模型运行时存储可以分成两部分，其一是模型参数，这部分规模是固定的，其二是中间激活，这部分和batch size、sequence length有线性关系，下面对两者分别分析。 模型参数 变量定义： 模型参数数量存储占用，以为单位 训练阶段 在训练阶段，采用Adam优化器，先看下Adam的公式SGD优化算法的各种变体。 Adam超参数： 学习率 惯性项 惯性项 衰减率 Adam更新公式： Adam中有和两个动量累积值，因此每个模型训练参数会对应4个浮点值，包括参数本身、梯度值、Adam两个动量累积值。这部分参数对精度要求较高，需要用到float32（4 bytes）存储，每个参数占用存储16 bytes。 因此，训练阶段全部模型参数共占用存储为： GPT3 175B模型，训练阶段参数存储占用为2595GB。 推理阶段 推理阶段只有前向过程，用float16存储的话，存储占用为： GPT3 175B模型，推理阶段参数存储占用为324GB。可以看到，A100单卡80G也无法放下，需要更低的存储精度或者多级存储方案，或者单机多卡。 中间激活 变量定义： 样本样本的序列长度 TensorFlow、PyTorch、MXNet等深度学习框架以逻辑计算图描述模型，以运行时计算图启动计算，计算图以Tensor（数据）和Operatopn（算子）组织，Operation依赖输入Tensor，通过内部计算得到输出Tensor。更具体一点，前向计算过程中，Operation接收上一Operation产出的激活Tensor和本Operation模型参数Tensor，计算得到激活Tensor给下游Operation，既： 后向计算过程，除上述Tensor外，还有下游Operation后向传回来的梯度Tensor，既： 其中，需要传给上游Operation用于后向传播的梯度计算，和传给优化器用于梯度更新。模型参数param和其梯度param grad在上一节内容已经包括在内，所以本节只考虑activation相关的Tensor存储占用即可。Operation内部也有中间变量，这些临时变量生命中期较短，因此本文讨论存储占用时，不考虑这部分，只考虑计算图中Operation之间的Tensor。一个Operation的输出Tensor是下游多个Operation的输入Tensor，此Tensor只占用一份存储即可，因此下文统计存储时只考虑Operation的输出Tensor。中间激活也和Operation的数量或粒度有关，细粒度Operation接口的激活值更多，粗粒度Operation将部分激活转化成了内部临时变量，因此接口的激活值更少。 下面按Operation进行分析。训练阶段经常使用混合精度训练，推理阶段也会采用量化，因此下面统一以半精度float16（2 bytes）进行浮点存储和计算。 Embedding embedding层是lookup操作，输入是词序列，输出形状是，存储占用为： Transformer Blocks transformer block的计算图如下，每个transformer block主要包含四部分，既multi-head attention和mlp，以及两个add&amp;norm。 Multi-head Attention multi-head attention结构如图： 变量定义： 、矩阵的维度矩阵的维度和往往一样，都表示为数量数量 multi-head attention的计算逻辑为： 其中，。 矩阵乘法算子的输入激活Tensor是E，E在第一个block是词本身embedding和position embedding之和，在其他block是上游block的输出，E的形状为，乘法输出Tensor形状为，因此存储占用为，和同； Softmax算子的输入Tensor为和，输出形状为，存储占用为； 的输入Tensor为和，输出为，存储为； 每个head的存储为，共个head，存储占用为：； concat的输入为个，输出为，存储为； 输入为激活和参数，输出为，因此存储为。 实际实现时，往往不会使用concat，而是将多头的Q、K、V合并成大矩阵，因此将concat存储忽略。综上，multi-head attention的输入存储总占用为： MLP multi-head attention后面，接两层的全连接网络，计算逻辑为： 其中，。 矩阵乘法算子的输入激活Tensor x是multi-head attention输出，形状为，输出Tensor形状为，因此存储占用为； 加法部分输入是激活和参数，输出是，存储占用为； 输入和输出都是，输入存储为； 的输入是激活和参数，输出是，输入存储为； 加法部分输入是激活和参数，输出是，输入存储占用为； 综上，mlp部分的存储占用为： Add&amp;Norm add部分的输入激活可以与multi-head attention和mlp里的输入共享存储，因此不用计算。norm的输入和输出都是，两个norm的存储占用为。 所以，add&amp;norm部分的存储占用为： 中间激活存储占用 综上，每个transformer block的存储占用为： 共个block，因此总存储占用为： 训练阶段 在训练阶段，中间激活需要保留用于反向传播的梯度计算，并且每个激活tensor都对应一个梯度tensor，因此存储占用翻倍，既。 按GPT3 175B配置计算： 按的话，每种的存储占用为： 中间激活存储(GB) 128 42624 512 170496 1024 340992 4096 1363968 这里将较小的embedding存储忽略，可以看到，相比模型参数部分占用的2595GB，中间激活存储占比更大，需要借助混合并行（数据并行、流水并行、模型并行）、recompute、ZeRO等技术来解决。在batch为128时，存储消耗2595+42624G，需要近600张A100 80G卡。 推理阶段 在推理阶段，中间激活使用完成后可以立即释放。多个block串行计算，block间可以共享内存。block内部有些tensor也串行依赖，tensor使用完成后即可释放。因此，推理阶段最大存储占用比单block存储大小更小一点。 按GPT3 175B配置计算： 按的话，约为1.7G，相比于模型参数占用324G很小，因此推理阶段存储主要消耗在模型参数上。 参考资料 Attention Is All You Need Language Models are Few-Shot Learners 分析transformer模型的参数量、计算量、中间激活、KV cache DeepSpeed之ZeRO系列：将显存优化进行到底 巨型AI模型背后的分布式训练技术 巨型AI模型背后的分布式训练技术（二） OneFlow —— 让每一位算法工程师都有能力训练GPT 千亿参数开源大模型BLOOM背后的技术","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"ChatGPT量化分析（一） - 模型参数分析","slug":"transformer_quant_analysis_first","date":"2023-05-31T07:04:39.000Z","updated":"2023-09-19T02:53:03.257Z","comments":true,"path":"2a29fbbd/","permalink":"https://www.mathmach.com/2a29fbbd/","excerpt":"","text":"背景 模型结构 参数量分析 Embedding层 Transformer Blocks层 Multi-head Attention MLP Transformer Block参数量 模型总参数量 各配置对总参数量的影响 参考资料 背景 ChatGPT出现后，惊人的效果完全颠覆了业界人员包括笔者的认知，抛开其模型细节层面的因素，已公开的训练方法，需要巨量的数据和计算资源，门槛非常高。本文基于公开资料，希望以量化方式分多篇介绍ChatGPT的分析结论，具体内容包含以下三篇，本文为模型参数分析篇。 ChatGPT量化分析（一） - 模型参数分析 ChatGPT量化分析（二） - 存储占用分析 ChatGPT量化分析（三） - 计算量分析 模型结构 基于Transformer结构的encoder-decoder模型如图： encoder编码器将输入词序列转换成一个向量序列，decoder解码器生成输出词序列。解码时一个个词按顺序解码，在解码时，根据和，生成。 ChatGPT的基础模型为Transformer，采用的是decoder-only结构。 参数量分析 输入词序列首先lookup词向量，得到，然后经过多个transformer block，参数分布在embedding层和transformer block中。 Embedding层 变量定义： 词的词表大小上文窗口或者序列最大长度 对于可训练的position embedding，其参数量为，一般在整体中占比不大，并且很多模型都为固定参数，因此将它忽略。 所以，embedding层的参数量为： Transformer Blocks层 transformer block计算图如下，每个transformer block的参数分布在两部分中，既multi-head attention和mlp。 Multi-head Attention multi-head attention结构如图： 变量定义： 、矩阵的维度矩阵的维度和往往一样，都表示为数量数量 multi-head attention的计算逻辑为： 其中，。 所以，multi-head attention的参数量为： MLP multi-head attention后面，接两层的全连接网络，计算逻辑为： 其中，。 所以，mlp的参数量为： Transformer Block参数量 根据multi-head attention和mlp，得到每个transformer block的参数量为： 共个transformer block，参数量为： 模型总参数量 最终，Transformer的总参数量为： 在GPT3中，，，都与Transformer原始论文一致，上式也可写为： 根据GPT3 175B的模型参数配置，并假设，代入公式计算得到的参数量为174566473728，与175B非常接近。 各个参数对模型大小的影响力度不同，这里需要特别注意的配置，如果，GPT3 175B大小的模型将会降低至87B，可见对模型参数量的影响力度非常大，但它对模型效果影响在论文中并没有提及。 各配置对总参数量的影响 对参数配置进行求导，得到： 我们使用GPT3 175B配置代入得到： 参数配置 梯度值 14175872 2359392 452984832 1812000768 603979776 可以看到，、、对参数量的影响最大，在GPT3中训练了不同规模的模型，主要通过调整这几个参数。 参考资料 Attention Is All You Need Language Models are Few-Shot Learners","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"Softmax近似方法之NCE、NEG、Sampled Softmax对比","slug":"approximate_softmax_methods","date":"2023-05-08T02:10:52.000Z","updated":"2023-09-19T02:53:03.253Z","comments":true,"path":"a817e3bf/","permalink":"https://www.mathmach.com/a817e3bf/","excerpt":"","text":"背景 NCE NEG Sampled Softmax 总结 参考资料 背景 在Noise Contrastive Estimation - 理论篇和Sampled Softmax - 理论篇中，针对大规模多分类概率模型的学习问题进行了NCE和Sampled Softmax的理论介绍。考虑到实际场景中，有一类问题是条件概率预估。假设给定了一个上下文，预估的条件概率，既。为了与前面两篇文章中的公式尽量兼容，下面将简写为。 其中，，是归一化因子。 在文章TensorFlow Candidate Sampling中，很多地方直接使用了，缺乏理论支持，笔者认为不太正确，所以在本文记录下个人理解。 NCE NCE的学习目标是： 其中，是可学习参数。 最终学到的概率模型是： NCE将原始Softmax多分类问题转化为多个二分类问题，既。二分类的odds计算如下： 那么， 所以，NCE的拟合的是。 二分类问题的损失函数为交叉熵损失，既： 其中，是正样本集合大小，是每个正样本的负采样数目。 NEG NEG将NCE学习目标进行简化，忽略了，NEG的学习目标为： 其中，是可学习参数。 最终学到的概率模型与NCE稍有不同，既： NEG的学习目标拟合，既： 损失函数同NCE一致，既： Sampled Softmax Sampled Softmax的学习目标同NCE一致，既： 其中，是可学习参数。 最终学到的概率模型为： 其中，是一个与当前无关的常数项。 多分类问题的损失函数为： 总结 方法 损失函数 NCE NEG 同NCE SSM 同NCE 参考资料 TensorFlow Candidate Sampling 一文搞懂Approximate Softmax：从公式到代码 Noise Contrastive Estimation - 理论篇 Sampled Softmax - 理论篇","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Numerical-Optimization","slug":"Numerical-Optimization","permalink":"https://www.mathmach.com/tags/Numerical-Optimization/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"}],"author":"formath"},{"title":"Sampled Softmax - 理论篇","slug":"sampled_softmax","date":"2023-04-07T14:39:28.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"fa54b17/","permalink":"https://www.mathmach.com/fa54b17/","excerpt":"","text":"背景 Sampled Softmax的优化目标 Sampled Softmax优化目标下的概率模型 Sampled Softmax效果的理论分析 概率模型收敛性分析 梯度值分析 参考资料 背景 我们有一个样本集合，它的概率分布为，我们希望学习一个分布来逼近。 其中，。 通过最大似然得到的log-likelihood损失函数： 接下来需要对公式进行求导，这里导数计算依赖。但是，在很多情况下并不容易求得。比如，在推荐系统领域，预测用户下一次点击某个item的概率，需要在全部item上计算，而item数量可能为千万甚至亿级。那么，怎么解决这个问题呢？ Sampled Softmax的优化目标 Sampled Softmax的核心思想是将上述问题改造为一个类别少很多的多分类问题（注意体会这里与Noise Contrastive Estimation - 理论篇的区别）。 除了样本集合，我们再根据一个人为设定的概率采样若干样本集合，的样本量是的倍。即对每个正样本，采样个负样本。其中，负样本集合称为噪声样本。 这样，对于每个正样本和它对应的个负样本，共个样本，记为集合，从中选出一个样本，选中正样本的概率为（以下忽略）： 其中，是全部样本集合，是从C-x中选出全部剩余样本，并且L-C中选出个样本的概率乘积。K(C)与当前x无关，是常数项。其实，就是用小样本集合的p(x|C)去近似拟合完整样本集合的p(x|L)=p(x)$。 将公式代入，进一步可得： 其中， 这里把、将它变为一个可学习参数，总的学习参数为。可以看到，的形式与NCE一样。变为可学习参数后，不能保证概率之和为1，既概率没有归一化，所以公式第三行变成近似，归一化后的概率变为： 最后，我们的优化目标为最大化选中正样本的概率，损失函数既： 损失函数进一步可以写成以下形式： 其中，是正样本集合的样本数量，是正样本对应的正样本加负采样集合。 Sampled Softmax优化目标下的概率模型 上文我们只定义了，那么是什么样呢？ 可得： 与公式相比，难以计算的没有了，代替以可学习偏差项和。 Sampled Softmax效果的理论分析 Sampled Softmax通过优化目标和概率模型的调整，达到了计算可行性。但是，能够保证学习出的概率模型没有跑偏吗，既能近似吗？ 概率模型收敛性分析 其中，与有关，所以最小化与最小化有偏差，既： 梯度值分析 Sampled Softmax with Random Fourier Features给出了梯度偏差的上下界，既的梯度是有偏的。 参考资料 一文搞懂Approximate Softmax：从公式到代码 TensorFlow Candidate Sampling Noise Contrastive Estimation - 理论篇 Sampled Softmax with Random Fourier Features Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Numerical-Optimization","slug":"Numerical-Optimization","permalink":"https://www.mathmach.com/tags/Numerical-Optimization/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"Noise Contrastive Estimation - 理论篇","slug":"noise_contrastive_estimation","date":"2023-03-15T06:13:23.000Z","updated":"2023-09-19T02:53:03.255Z","comments":true,"path":"b5ec3256/","permalink":"https://www.mathmach.com/b5ec3256/","excerpt":"","text":"背景 NCE的优化目标 NCE优化目标下的概率模型 NCE效果的理论分析 概率模型收敛性分析 梯度值分析 NCE的变体 NEG 的取舍 参考资料 背景 我们有一个样本集合，它的概率分布为，我们希望学习一个分布来逼近。 其中，。 通过最大似然得到的log-likelihood损失函数： 接下来需要对公式进行求导，这里导数计算依赖。但是，在很多情况下并不容易求得。比如，在推荐系统领域，预测用户下一次点击某个item的概率，需要在全部item上计算，而item数量可能为千万甚至亿级。那么，怎么解决这个问题呢？ NCE的优化目标 NCE的核心思想是将上述问题改造为多个二分类问题。 除了样本集合，我们再根据一个人为设定的概率采样若干样本集合，的样本量是的倍。即对每个正样本，采样个负样本。其中，负样本集合称为噪声样本。 这样，对于每个正样本和它对应的个负样本，可以生成个二分类任务。个样本中的每个样本，如果它属于则为正类，，如果属于则为负类，。 得到以下概率： 那么，条件概率分布为： 我们希望学习一个分布来逼近，既： 下文简写为和。 是二分类问题，我们将它继续推导为如下形式： 其中， 这里我们把变成可学习参数，所以总的参数变为。 最后，我们的优化目标为交叉熵损失： 损失函数进一步可以写成以下形式： 其中，是正样本集合的样本数量。 NCE优化目标下的概率模型 上文我们只定义了，那么是什么样呢？ 可得： 与公式相比，难以计算的没有了，代替以可学习偏差项。在实际实现中是个固定值，的选取往往也比较简单，也可以变成常数项。另外，为了保证，需要通过模型来学习达到这一目的，通过梯度下降迭代求解无法完全保证这一点。在实际使用中，一般得到logit的值或更前面的向量表示即可，是否能归一化并不影响使用，所以问题不大。 NCE效果的理论分析 NCE通过优化目标和概率模型的调整，达到了计算可行性。但是，能够保证学习出的概率模型没有跑偏吗，既能近似吗？ 概率模型收敛性分析 首先分析在下收敛到哪里？ 因为、与参数无关，所以以上优化目标中增加两项后不影响最终，可以写成： 已知KL散度非负，所以当时，达到最小值。此时， 既： 这样可以理论上保证收敛到，优化目标能够保证最优解情况下的没有跑偏。 梯度值分析 概率模型收敛性分析只能保证在全局函数空间，可以找到最优。但是，工程实现时，将函数空间做了限制，能保证效果吗？ 因为需要通过梯度下降进行迭代求解，所以这里通过两者的梯度进行对比。 首先对进行求导： 然后对进行求导： 可以看出，比仅多了一项。当时，等于，既： 到这里可以看到，虽然NCE学习出的概率模型形式与原始Softmax形式有区别，但通过优化目标的调整，在极限条件下能够在梯度下降过程中近似MLE的效果。并且，在实际使用时往往接近1，导致和的差别并不大，在非极限条件下也能够有很好的效果。 NCE的变体 NEG 是标准NCE下的logit，在此起了修正作用。实际的工作中，比如推荐算法中常用的一个变体Negative Sampling（NEG）方法，忽略掉了，只使用，并且采用相同的损失函数，获得了不错的效果，那么NEG是否有理论保证呢？ 从上文的NCE概率模型收敛性分析中可以看出，不管任何形式，都可以保证收敛到。从NCE梯度值分析中亦可得出，只要，就能保证梯度与原问题近似。这里，可以是可学习的或者人工设定的固定值，并且固定值不能太大或太小，否则会把推到一个很大或很小的值域，造成训练中的数值问题。总之，NEG与NCE一样，也有理论保证，所以可以得到媲美NCE的效果。 的取舍 里面的可以去掉吗？ 如果的范围很大，可以去掉，只学习，就能保证覆盖的尺度空间。如果的范围受限，比如推荐算法里用两个向量的作为，为了保证的范围足够大，建议保留可学习的参数。总之，要保证能够覆盖区间。 参考资料 “噪声对比估计”杂谈：曲径通幽之妙 Lei Mao Blog - Noise Contrastive Estimation Notes on Noise Contrastive Estimation and Negative Sampling Noise-contrastive estimation: A new estimation principle for unnormalized statistical models","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Numerical-Optimization","slug":"Numerical-Optimization","permalink":"https://www.mathmach.com/tags/Numerical-Optimization/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"TensorFlow多Worker Barrier同步实现","slug":"tensorflow_barrier","date":"2022-09-25T10:32:05.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"b2f65b04/","permalink":"https://www.mathmach.com/b2f65b04/","excerpt":"","text":"背景 Barrier机制实现 训练代码 背景 同步机制在TensorFlow等分布式机器学习框架中非常重要，比如TensorFlow有以下场景需要做同步： * 当chief worker训练完一轮后，保存模型前需要等所有worker都完成再保存模型。 * BSP方式的SGD训练，需要每个batch做同步。 如果不做同步可能会出现如下问题： * TensorFlow大部分使用方案都是异步SGD，而且使用global_step做停止条件，不能保证所有worker负责的数据训练相同的轮数，速度快的worker所负责的数据将会获得更多step。 * chief worker结束时会保存模型参数，但还存在其他worker没结束，所以模型没有完全训练完整。 最优的方式应该是这样： epoch = 0while epoch &lt; max_epoch: train_one_epoch # 跑一轮数据 barrier # 卡在这里，等所有worker都跑完一轮数据 save checkpoint # 保存这一轮的模型 do evaluation # 跑一遍验证集数据 epoch++ # 进入下一轮 那怎样实现barrier机制呢？ Barrier机制实现 具体原理就是在PS:0节点上添加和worker数目一样的一组计数变量counter_vars，初始化时为0，每当worker结束一轮训练后，将自己的worker_index对应的counter_var增加1，然后依次遍历其他worker对应的counter_var，直到所有worker的counter_var都等于1说明所有worker都完成这一轮训练了，然后就可以进入下一轮训练。当然，barrier也可以用于其他任意同步的方式，比如退出时也可以加个barrier，等所有worker都结束后保存模型再退出。 class Barrier(object): def __init__(self, worker_num, barrier_num, sleep_time_ms=10): self._worker_num = worker_num self._barrier_num = barrier_num self._sleep_time_ms = sleep_time_ms self._counter_vars = [] self._counter_add_ops = [] self._counter_reset_ops = [] ps_device = '/job:ps/task:0/cpu:0' with tf.device(ps_device): for i in range(self._barrier_num): for j in range(self._worker_num): counter_var = tf.get_variable( 'counter-{}_{}'.format(i, j), (), tf.int32, initializer=tf.zeros_initializer ) self._counter_vars.append(counter_var) self._counter_add_ops.append(counter_var.assign_add(1, use_locking=True)) self._counter_reset_ops.append(counter_var.assign(0, use_locking=True)) def barrier_reset(self, session, worker_index, barrier_index): index = barrier_index * self._worker_num + worker_index session.run(self._counter_reset_ops[index]) def barrier(self, session, worker_index, barrier_index, epoch): for task_index in range(self._worker_num): if task_index == worker_index: session.run(self._counter_add_ops[barrier_index * self._worker_num + worker_index]) index = barrier_index * self._worker_num + task_index count = session.run(self._counter_vars[index]) retry_num = 0 while count &lt; epoch: time.sleep(self._sleep_time_ms) retry_num += 1 count = session.run(self._counter_vars[index]) if retry_num == 1: tf.logging.info(\"{} wait for {}_{} to be completed\".format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()), task_index)) 训练代码 首先不能使用QueueRunner读数据，因为它无法实现按轮次读取，需要使用DataSet来读取数据，保证worker知道每轮数据读完了。 def _parse_function(example_proto): features = {} features['label'] = tf.FixedLenFeature([], tf.float32) features['feature'] = tf.FixedLenFeature([100], tf.int64) instance = tf.parse_example(example_proto, features) label = instance['label'] feature = instance['feature'] return label, featureif job_name == 'ps': with tf.device('/cpu:0'): server.join()elif job_name == 'worker': with tf.device(param_server_device): # dataset input dataset = tf.data.TFRecordDataset(file_name) dataset = dataset.prefetch(buffer_size=batch_size*100) dataset = dataset.shuffle(buffer_size=batch_size*10) dataset = dataset.batch(batch_size) dataset = dataset.map(_parse_function, num_parallel_calls=4) train_iterator = dataset.make_initializable_iterator() train_label, train_feature = train_iterator.get_next() # forward pass model = ... train_logits = model.forward(train_feature) # loss train_label = tf.to_int64(train_label) train_cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits( logits=train_logits, labels=train_label) train_loss = tf.reduce_mean(train_cross_entropy, name='loss') # optimizer opt = tf.train.AdamOptimizer() train_op = opt.minimize(train_loss) # barrier barrier_op = barrier.Barrier(self.num_worker, 2) # 下面需要两处做barrier，所以为2 # job process with tf.Session() as sess: # init sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()]) # training process epoch_num = 0 barrier_op.barrier(sess, self.task_index, 0, epoch_num) # 等所有worker都启动再开始训练 while epoch_num &lt; max_epoch: sess.run(train_iterator.initializer) # 每轮开始先初始化数据 while True: try: sess.run(train_op) except tf.errors.OutOfRangeError: break barrier_op.barrier(sess, self.task_index, 1, epoch_num) # 等所有worker结束这轮训练 #保存这一轮的checkpoint epoch_num += 1 # 进入下一轮","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"TensorFlow分布式任务DataSet卡住问题","slug":"tensorflow_dataset_hangs","date":"2022-02-25T10:32:05.000Z","updated":"2023-09-19T02:53:03.257Z","comments":true,"path":"97b8f613/","permalink":"https://www.mathmach.com/97b8f613/","excerpt":"","text":"背景 复现条件 解决方案 背景 2018年，公司的分布式模型训练普遍向TensorFlow on Yarn迁移。在公司的Hadoop集群上，使用TensorFlow通过DataSet读数据方式进行分布式训练时，在每个Epoch的最后一个Batch会卡住，导致任务一直停在那里无法结束。集群节点都是CentOS, linux kernel 3.10.0。如果用老的Queue读取数据不会出现这个问题，并且这个问题不是必现，只有在分布式且节点比较多的时候发生的概率比较高。 复现条件 开始时我尝试将把线程数inter_op_parallelism_threads和intra_op_parallelism_threads都设为1，并且PS节点数等于1的话，一定不会出现这个问题。 server_config = tf.ConfigProto(inter_op_parallelism_threads=1, intra_op_parallelism_threads=1)self.server = tf.train.Server(self.cluster, job_name=self.job_name, task_index=self.task_index, config=server_config) 经过多次尝试，发现只有在inter_op_parallelism_threads大于1并且PS节点数大于1的情况下才会偶发，其他条件下一定不会出现，和intra_op_parallelism_threads的设置没有关系。 出现问题的代码，是最常用的使用方式。 def data_iter(batch_size=1000): def _parse_function(examples): features = {} features['label'] = tf.FixedLenFeature([1], tf.float32) features['user_id'] = tf.FixedLenFeature([1], tf.int64) features['item_id'] = tf.FixedLenFeature([1], tf.int64) instance = tf.parse_example(examples, features) return instance['user_id'], instance['item_id'], instance['label'] with tf.name_scope('input'): files = tf.data.Dataset.list_files('./inputs/part-*') dataset = files.apply(tf.contrib.data.parallel_interleave( lambda file: tf.data.TFRecordDataset(file), cycle_length=4, sloppy=True)) dataset = dataset.prefetch(buffer_size=batch_size*2) dataset = dataset.batch(batch_size) dataset = dataset.map(_parse_function, num_parallel_calls=4) iterator = dataset.make_initializable_iterator() return iteratordef model(user_id, item_id): ... user_embedding = tf.embedding_lookup(user_id) item_embedding == tf.embedding_lookup(item_id) return tf.reduce_sum(query_embedding * item_embedding, 1, keep_dims=True)# 图构造部分train_iterator = data_iter(FLAGS.batch_size)train_user_id, train_item_id, train_label = train_iterator.get_next()train_score = model(train_user_id, train_item_id)train_loss = some_loss_function(train_score, train_label)opt = tf.train.AdamOptimizer(learning_rate=0.001)train_op = opt.minimize(train_loss)# 执行部分with tf.Session(...) as sess: ... while True: try: sess.run(train_op) except tf.errors.OutOfRangeError: break 解决方案 从问题表象来看，是DataSet多线程读取数据的问题，看了一段时间TensorFlow这部分的代码，没有找到解决方案。但是，从使用层面来看，DataSet主要是解耦了数据读取和模型执行部分，因为大部分模型来说，数据部分往往是瓶颈，两部分解耦后并行执行可以大大提高训练的吞吐效率。另外，session执行时直接执行最终的train_op，train_op依赖的数据读取op会自动执行。 sess.run(train_op) 所以直觉上，我怀疑很可能是模型部分和读数据部分在线程协调上出了问题。通过将读数据和模型执行两部分强制分开，问题果然消失了。 feature_value = sess.run([feature_dataset_next_iter])sess.run(train_op, feed_dict={feature_placeholder: feature_value}) 完整的代码如下。 def data_iter(batch_size=1000): def _parse_function(examples): features = {} features['label'] = tf.FixedLenFeature([1], tf.float32) features['user_id'] = tf.FixedLenFeature([1], tf.int64) features['item_id'] = tf.FixedLenFeature([1], tf.int64) instance = tf.parse_example(examples, features) return instance['user_id'], instance['item_id'], instance['label'] with tf.name_scope('input'): files = tf.data.Dataset.list_files('./inputs/part-*') dataset = files.apply(tf.contrib.data.parallel_interleave( lambda file: tf.data.TFRecordDataset(file), cycle_length=4, sloppy=True)) dataset = dataset.prefetch(buffer_size=batch_size*2) dataset = dataset.batch(batch_size) dataset = dataset.map(_parse_function, num_parallel_calls=4) iterator = dataset.make_initializable_iterator() return iteratordef model(user_id, item_id): ... user_embedding = tf.embedding_lookup(user_id) item_embedding == tf.embedding_lookup(item_id) return tf.reduce_sum(query_embedding * item_embedding, 1, keep_dims=True)# 图构造部分: 模型部分使用placeholder，不直接使用DataSet.iterator的输出train_iterator = data_iter(FLAGS.batch_size)train_user_id, train_item_id, train_label = train_iterator.get_next()train_user_id_placeholder = tf.placeholder(tf.int64, [None, 1], name=\"train_user_id_placeholder\")train_item_id_placeholder = tf.placeholder(tf.int64, [None, 1], name=\"train_item_id_placeholder\")train_label_placeholder = tf.placeholder(tf.float32, [None, 1], name=\"train_label_placeholder\")train_score = model(train_user_id_placeholder, train_item_id_placeholder)train_loss = some_loss_function(train_score, train_label_placeholder)opt = tf.train.AdamOptimizer(learning_rate=0.001)train_op = opt.minimize(train_loss)# 执行部分with tf.Session(...) as sess: ... while True: try: # 将数据读取和模型部分拆开，分别执行sess.run train_user_id_val, train_item_id_val, train_label_val = sess.run([train_user_id, train_item_id, train_label]) sess.run(train_op, feed_dict={ train_user_id_placeholder: train_user_id_val, train_item_id_placeholder: train_item_id_val, train_label_placeholder: train_label_val }) except tf.errors.OutOfRangeError: break 这个问题在TensorFlow-1.x都存在，在2.x上就不了解了，下一步需要在核心层面解决这个问题。","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"使用TensorFlow C++ API构建线上预测服务 - 篇3","slug":"tensorflow_c++_api_prediction_third","date":"2021-10-22T03:32:05.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"832a0a1e/","permalink":"https://www.mathmach.com/832a0a1e/","excerpt":"","text":"Freeze Graph 具体方案 例子 训练网络 预测网络 前两篇 * 使用TensorFlow C++ API构建线上预测服务 - 篇1 * 使用TensorFlow C++ API构建线上预测服务 - 篇2 在线下训练时，为了效率考虑，我们经常把数据转成TFRecord格式，然后直接调用TensorFlow提供的Reader来读入TFRecord数据。这样在生成的graph.pb中，Reader会对应多个节点，如果在c++中直接导入这个graph.pb我们就不能使用std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;&gt;作为session.Run(...)的输入了。这篇文章讲解一下怎样处理这种情况。 Freeze Graph 回顾一下上篇讲到的怎样使用freeze graph。 python ../../python/freeze_graph.py \\ --checkpoint_dir='./checkpoint' \\ --output_node_names='predict/add' \\ --output_dir='./model' 其实，这里还有一个可选输入，即--graph_pb，如果设定这个，相当于不用meta文件里的graph，而是用这个网络去freeze。 这个参数不一定非要用训练时保存的网络，可以指定任何网络。讲到这里你可能就明白我们的方案是什么了。 python ../../python/freeze_graph.py \\ --checkpoint_dir='./checkpoint' \\ --graph_pb='./model/predict_graph.pb' \\ --output_node_names='predict/add' \\ --output_dir='./model' 具体方案 由于session.Run(...)只能接受std::vector&lt;std::pair&lt;std::string, tensorflow::Tensor&gt;&gt;作为网络输入，那么我们可以构造一个新网络，这个网络和训练时的网络几乎一样，只不过输入部分不使用Reader，而是用tf.Placeholder代替。我们把新网络保存成predict_graph.pb，把它和训练产出的checkpoint进行freeze，即可得到可以用c++导入的一个新网络pb，用这个pb上线就可以了。 例子 训练网络 # inputwith tf.name_scope('input'): filename_queue = tf.train.string_input_producer( tf.train.match_filenames_once(file_name), num_epochs=max_epoch) serialized_example = self.Decode(filename_queue) capacity = thread_num * batch_size + min_after_dequeue batch_serialized_example = tf.train.shuffle_batch( [serialized_example], batch_size=batch_size, num_threads=thread_num, capacity=capacity, min_after_dequeue=min_after_dequeue) features = {} features['label'] = tf.FixedLenFeature([], tf.float32) features['sparse_id'] = tf.VarLenFeature(tf.int64) features['sparse_val'] = tf.VarLenFeature(tf.float32) instance = tf.parse_example(batch_serialized_example, features) label = instance['label'] sparse_id = instance['sparse_id'] sparse_val = instance['sparse_val']# network with tf.variable_scope(\"emb_layer\"): embedding_variable = tf.Variable(tf.truncated_normal([100000, 50], stddev=0.05), name='emb_var') embedding = tf.nn.embedding_lookup_sparse(embedding_variable, sparse_id, sparse_val], \"mod\", combiner=\"sum\")... 预测网络 # inputwith tf.name_scope('input'): with tf.variable_scope('sparse_field'): with tf.variable_scope('index'): sparse_index = tf.placeholder(tf.int64) with tf.variable_scope('id'): sparse_ids = tf.placeholder(tf.int64) with tf.variable_scope('value'): sparse_vals = tf.placeholder(tf.float32) with tf.variable_scope('shape'): sparse_shape = tf.placeholder(tf.int64) sparse_id = tf.SparseTensor(sparse_index, sparse_ids, self.sparse_shape) sparse_val = tf.SparseTensor(sparse_index, sparse_vals, sparse_shape) with tf.variable_scope('label'): label = tf.placeholder(tf.float32)# networkwith tf.variable_scope(\"emb_layer\"): embedding_variable = tf.Variable(tf.truncated_normal([100000, 50], stddev=0.05), name='emb_var') embedding = tf.nn.embedding_lookup_sparse(embedding_variable, sparse_id, sparse_val], \"mod\", combiner=\"sum\")... 使用训练网络训练后保存checkpoint，然后保存预测网络的graph.pb，直接调用freeze把两者生成一个新的graph.pb即可，c++线上预测时只需为预测网络的输入部分构造所需几个Tensor作为输入即可。","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"使用TensorFlow C++ API构建线上预测服务 - 篇2","slug":"tensorflow_c++_api_prediction_second","date":"2021-10-11T03:32:05.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"f42d3a88/","permalink":"https://www.mathmach.com/f42d3a88/","excerpt":"","text":"稀疏数据下的数据预处理 训练中保存模型和参数 保存网络结构 保存模型参数 TensorFlow C++ API导入模型和参数 分别导入网络结构和模型参数 导入网络结构 导入模型参数 网络结构和模型参数整合成一个文件 TensorFlow C++ API构造Sparse Tensor 参考 之前的一篇文章中使用TensorFlow C++ API构建线上预测服务 - 篇1，详细讲解了怎样用TensorFlow C++ API导入模型做预测，但模型c = a * b比较简单，只有模型结构，并没有参数，所以文章中并没讲到怎样导入参数。本文使用一个复杂的模型讲解，包括以下几个方面： * 针对稀疏数据的数据预处理 * 训练中保存模型和参数 * TensorFlow C++ API导入模型和参数 * TensorFlow C++ API构造Sparse Tensor做模型输入 稀疏数据下的数据预处理 稀疏数据下，一般会调用TensorFlow的embedding_lookup_sparse。 embedding_variable = tf.Variable(tf.truncated_normal([input_size, embedding_size], stddev=0.05), name='emb')embedding = tf.nn.embedding_lookup_sparse(embedding_variable, sparse_id, sparse_value, \"mod\", combiner=\"sum\") 上面代码中，embedding_variable就是需要学习的参数，其中input_size是矩阵的行数，embedding_size是矩阵的列数，比如我们有100万个稀疏id，每个id要embedding到50维向量，那么矩阵的大小是[1000000, 50]。sparse_id是要做向量化的一组id，用SparseTensor表示，sparse_value是每个id对用的一个value，用作权重，也用SparseTensor表示。 这里要注意，如果id是用hash生成的，不保证id是0,1,2,3, ...这种连续表示，需要先把id排序后转成连续的，并且把input_size设成大于排序后最大的id，为了节省空间往往设成排序后最大id+1。因为用id去embedding_variable矩阵查询命中哪行的时候，使用id mod Row(embedding_variable)或其他策略作为命中的行数，如果不保证id连续，可能会出现多个id命中同一行的错误情况。另外，如果不把id排序后转成连续id，那input_size需要设成原始id中的最大id，如果是hash生成的那么最大id值非常大，做成矩阵非常大存不下和矩阵存在空间浪费，因为有些行肯定不会被命中。 另外一个点，目前TensorFlow不支持sparse方式的查询和参数更新，每次查询更新都要pull&amp;push一个矩阵全量数据，造成网络的堵塞，速度过慢，所以一般来说不要使用太大的embedding矩阵。 训练中保存模型和参数 TensorFlow保存模型时分为两部分，网络结构和参数是分开保存的。 ## 保存网络结构 运行以下命令，成功后会看到一个名为graph.pb的pb二进制文件。后续如果使用TensorFlow官方提供的freeze_graph.py工具时必需这个文件，当然，如果对freeze_graph.py的代码比较熟悉，可以使用比较trick的方式，这样只需要参数文件，而不需要graph.pb了。 tf.train.write_graph(sess.graph.as_graph_def(), FLAGS.model_dir, 'graph.pb', as_text=False) ## 保存模型参数 运行以下命令，会在FLAGS.model_dir目录下保存多个前缀为model.checkpoint的文件。 saver = tf.train.Saver()saver.save(sess, FLAGS.model_dir + \"/model.checkpoint\") 比如，成功后在FLAGS.model_dir目录下会看到以下几个文件。其中，model.checkpoint.meta包含了网络结构和一些其他信息，所以也包含了上面提到的graph.pb；model.checkpoint.data-00000-of-00001保存了模型参数，其他两个文件辅助作用。 -rw-r--r-- 1 user staff 89 10 11 11:32 checkpoint-rw-r--r-- 1 user staff 225136 10 11 11:32 model.checkpoint.data-00000-of-00001-rw-r--r-- 1 user staff 1506 10 11 11:32 model.checkpoint.index-rw-r--r-- 1 user staff 369379 10 11 11:32 model.checkpoint.meta TensorFlow C++ API导入模型和参数 主要有两种方法： * 分别导入网络结构和模型参数 * 线下先把网络结构和模型参数整合成一个文件，只用导入这个文件即可 分别导入网络结构和模型参数 导入网络结构 以上文的graph.pb为例 // 导入网络结构GraphDef graph_def;status = ReadBinaryProto(Env::Default(), std::string(\"graph.pb\"), &amp;graph_def);if (!status.ok()) { throw runtime_error(\"Error loading graph: \" + status.ToString());}// 把网络设置到Session里status = session-&gt;Create(graph_def);if (!status.ok()) { throw runtime_error(\"Error set graph to session: \" + status.ToString());} ### 导入模型参数 这里注意要传入模型路径，既上文的FLAGS.model_dir。以FLAGS.model_dir=\"your_checkpoint_path\"为例 // 导入模型参数Tensor checkpointPathTensor(DT_STRING, TensorShape());checkpointPathTensor.scalar&lt;std::string&gt;()() = std::string(\"your_checkpoint_path\");status = session-&gt;Run( {{ graph_def.saver_def().filename_tensor_name(), checkpointPathTensor },}, {}, {graph_def.saver_def().restore_op_name()}, nullptr);if (!status.ok()) { throw runtime_error(\"Error loading checkpoint: \" + status.ToString());} 网络结构和模型参数整合成一个文件 One confusing part about this is that the weights usually aren't stored inside the file format during training. Instead, they're held in separate checkpoint files, and there are Variable ops in the graph that load the latest values when they're initialized. It's often not very convenient to have separate files when you're deploying to production, so there's the freeze_graph.py script that takes a graph definition and a set of checkpoints and freezes them together into a single file. 使用多个文件部署比较麻烦，如果能整个成一个独立文件会方便很多，因此，TensorFlow官方提供了freeze_graph.py工具。如果已经安装了TensorFlow，则在安装目录下可以找到，否则可以直接使用源码tensorflow/python/tools路径下freeze_graph.py。运行例子为： python ${TF_HOME}/tensorflow/python/tools/freeze_graph.py \\ --input_graph=\"graph.pb\" \\ --input_checkpoint=\"your_checkpoint_path/checkpoint_prefix\" \\ --output_graph=\"your_checkpoint_path/freeze_graph.pb\" \\ --output_node_names=Softmax 其中，input_graph为网络结构pb文件，input_checkpoint为模型参数文件名前缀，output_graph为我们的目标文件，output_node_names为目标网络节点名称，因为网络包括前向和后向网络，在预测时后向网络其实是多余的，指定output_node_names后只保存从输入节点到这个节点的部分网络。如果不清楚自己想要的节点output_node_names是什么，可以用下面的代码把网络里的全部节点名字列出来，然后找到自己想要的那个就行了。 for op in tf.get_default_graph().get_operations(): print(op.name) 得到freeze_graph.pb后，只导入网络结构即可，不再需要另外导入模型参数。 GraphDef graph_def;status = ReadBinaryProto(Env::Default(), std::string(\"freeze_graph.pb\"), &amp;graph_def); freeze_graph.py的更多参数可以看它的代码。 官方的freeze_graph.py工具需要在训练时同时调用tf.train.write_graph保存网络结构和tf.train.Saver()保存模型参数，之前讲过tf.train.Saver()保存的meta文件里其实已经包含了网络结构，所以就不用调用tf.train.write_graph保存网络结构，不过这时就不能直接调用官方的freeze_graph.py了，需要使用一点trick的方式将网络结构从meta文件里提取出来，具体代码可见https://github.com/formath/tensorflow-predictor-cpp/blob/master/python/freeze_graph.py，使用例子如下，其中checkpoint_dir的即上文的FLAGS.model_dir目录，output_node_names和官方freeze_graph.py的意思一致。 # this freeze_graph.py is https://github.com/formath/tensorflow-predictor-cpp/blob/master/python/freeze_graph.pypython ../../python/freeze_graph.py \\ --checkpoint_dir='./checkpoint' \\ --output_node_names='predict/add' \\ --output_dir='./model' TensorFlow C++ API构造Sparse Tensor 以LibFM格式数据为例，label fieldid:featureid:value ...。假如一个batch中有以下4条样本： 0 1:384:1 8:734:10 3:73:11 2:449:1 0:31:10 5:465:1 四个label可以表示成一个稠密Tensor，即 auto label_tensor = test::AsTensor&lt;float32&gt;({0, 0, 1, 0}); 剩余还有三个部分，分别是fieldid、featureid、value，每个部分都可以表示成一个SparseTensor，每个SparseTensor由3个Tensor组成。 Instance | SparseFieldId | SparseFeatureId | SparseValue |0 | 1, 8 | 384, 734 | 1.0, 1.0 |1 | 3 | 73 | 1.0 |2 | 2, 0 | 449, 31 | 1.0, 1.0 |3 | 5 | 465 | 1.0 | 以SparseFieldId部分为例，SparseTensor中的第一个Tensor表示每个id的行列坐标，比如Instance=0的FieldId=1为&lt;0, 0&gt;，Instance=0的FieldId=8为&lt;0, 1&gt;，Instance=2的FieldId=0为&lt;2, 1&gt;，总共6对，每对是个二元组，所以第一个Tensor为 auto fieldid_tensor_indices = test::AsTensor&lt;int64&gt;({0, 0, 0, 1, 1, 0, 2, 0, 2, 1, 3, 0}, {6, 2}); SparseTensor中的第二个Tensor表示id值，即 auto fieldid_tensor_values = test::AsTensor&lt;int64&gt;({1, 8, 3, 2, 0, 5}); 第三个Tensor表示样本行数和每条样本里最多有多少个id，所以是 auto fieldid_tensor_shape = TensorShape({4, 2}); 最后，fieldid部分的SparseTensor表示为 sparse::SparseTensor fieldid_sparse_tensor( fieldid_tensor_indices, fieldid_tensor_values, fieldid_tensor_shape); 其他两个部分，featureid和value同样可以用SparseTensor表示。最后，一个batch的libfm数据可以由4份数据来表示，这4份数据作为网络的input，运行Session.run即可得到输出。当然，线上预测时就没有label这一部分输入了。 * label的Tensor * fieldid的SparseTensor * featureid的SparseTensor * value的SparseTensor 参考 Exporting trained TensorFlow models to C++ the RIGHT way! Freeze Graph TensorFlow: How to freeze a model and serve it with a python API","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"使用TensorFlow C++ API构建线上预测服务 - 篇1","slug":"tensorflow_c++_api_prediction_first","date":"2021-10-09T10:32:05.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"6d246b32/","permalink":"https://www.mathmach.com/6d246b32/","excerpt":"","text":"使用Python接口训练模型 源码编译TensorFlow 使用TensorFlow C++ API编写预测代码 创建Session 导入模型 将模型设置到创建的Session里 设置模型输入 预测 查看预测结果 关闭Session 使用CMake构建预测代码 头文件路径 静态库路径 CMake构建 参考 目前，TensorFlow官方推荐使用Bazel编译源码和安装，但许多公司常用的构建工具是CMake。TensorFlow官方并没有提供CMake的编译示例，但提供了MakeFile文件，所以可以直接使用make进行编译安装。另一方面，模型训练成功后，官方提供了TensorFlow Servering进行预测的托管，但这个方案过于复杂。对于许多机器学习团队来说，一般都有自己的一套模型托管和预测服务，如果使用TensorFlow Servering对现存业务的侵入性太大，使用TensorFlow C++ API来导入模型并提供预测服务能方便的嵌入大部分已有业务方案，对这些团队来说比较合适。 本文以一个简单网络介绍从线下训练到线上预测的整个流程，主要包括以下几点： * 使用Python接口训练模型 * 使用make编译TensorFlow源码，得到静态库 * 调用TensorFlow C++ API编写预测代码，使用CMake构建预测服务 使用Python接口训练模型 这里用一个简单的网络来介绍，主要目的是保存网络结构和参数，用于后续的预测。 import tensorflow as tfimport numpy as npwith tf.Session() as sess: a = tf.Variable(5.0, name='a') b = tf.Variable(6.0, name='b') c = tf.multiply(a, b, name='c') sess.run(tf.global_variables_initializer()) print(a.eval()) # 5.0 print(b.eval()) # 6.0 print(c.eval()) # 30.0 tf.train.write_graph(sess.graph_def, 'simple_model/', 'graph.pb', as_text=False) 这个网络有两个输入，a和b，输出是c，最后一行用来保存模型到simple_model目录。运行后会在simple_model目录下生成一个graph.pb的protobuf二进制文件，这个文件保存了网络的结构，由于这个例子里没有模型参数，所以没有保存checkpoint文件。 源码编译TensorFlow 官方详细介绍可以看这里源码编译TensorFlow。其实很简单，以maxOS为例，只要运行以下命令即可，其他操作系统也有相应的命令。编译过程大概需要半小时，成功后会在tensorflow/tensorflow/contrib/makefile/gen/lib下看到一个100多MB的libtensorflow-core.a库文件。maxOS需要使用build_all_linux.sh，并且只能用clang，因为有第三方依赖编译时把clang写死了。 git clone https://github.com/tensorflow/tensorflow.gitcd tensorflowtensorflow/contrib/makefile/build_all_linux.sh 后续如果要依赖TensorFlow的头文件和静态库做开发，tensorflow/tensorflow/contrib/makefile目录下的几个目录需要注意： * downloads 存放第三方依赖的一些头文件和静态库，比如nsync、Eigen等 * gen 存放TensorFlow生成的C++ PB头文件、TensorFlow的静态库、ProtoBuf的头文件和静态库等等 使用TensorFlow C++ API编写预测代码 预测代码主要包括以下几个步骤： * 创建Session * 导入之前生成的模型 * 将模型设置到创建的Session里 * 设置模型输入输出，调用Session的Run做预测 * 关闭Session 创建Session Session* session;Status status = NewSession(SessionOptions(), &amp;session);if (!status.ok()) { std::cout &lt;&lt; status.ToString() &lt;&lt; std::endl;} else { std::cout &lt;&lt; \"Session created successfully\" &lt;&lt; std::endl;} 导入模型 GraphDef graph_def;Status status = ReadBinaryProto(Env::Default(), \"../demo/simple_model/graph.pb\", &amp;graph_def);if (!status.ok()) { std::cout &lt;&lt; status.ToString() &lt;&lt; std::endl;} else { std::cout &lt;&lt; \"Load graph protobuf successfully\" &lt;&lt; std::endl;} 将模型设置到创建的Session里 Status status = session-&gt;Create(graph_def);if (!status.ok()) { std::cout &lt;&lt; status.ToString() &lt;&lt; std::endl;} else { std::cout &lt;&lt; \"Add graph to session successfully\" &lt;&lt; std::endl;} 设置模型输入 模型的输入输出都是Tensor或Sparse Tensor。 Tensor a(DT_FLOAT, TensorShape()); // input aa.scalar&lt;float&gt;()() = 3.0;Tensor b(DT_FLOAT, TensorShape()); // input bb.scalar&lt;float&gt;()() = 2.0; 预测 std::vector&lt;std::pair&lt;string, tensorflow::Tensor&gt;&gt; inputs = { { \"a\", a }, { \"b\", b },}; // inputstd::vector&lt;tensorflow::Tensor&gt; outputs; // outputStatuc status = session-&gt;Run(inputs, {\"c\"}, {}, &amp;outputs);if (!status.ok()) { std::cout &lt;&lt; status.ToString() &lt;&lt; std::endl;} else { std::cout &lt;&lt; \"Run session successfully\" &lt;&lt; std::endl;} 查看预测结果 auto c = outputs[0].scalar&lt;float&gt;();std::cout &lt;&lt; \"output value: \" &lt;&lt; c() &lt;&lt; std::endl; 关闭Session session-&gt;Close(); 完整的代码在https://github.com/formath/tensorflow-predictor-cpp，路径为src/simple_model.cc。 使用CMake构建预测代码 这里主要的问题是头文件和静态库的路径要正确，包括TensorFlow以及第三方依赖。 以macOS为例，其他平台路径会不一样。 头文件路径 tensorflow // TensorFlow头文件tensorflow/tensorflow/contrib/makefile/gen/proto // TensorFlow PB文件生成的pb.h头文件tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/include // ProtoBuf头文件tensorflow/tensorflow/contrib/makefile/downloads/eigen // eigen头文件tensorflow/tensorflow/contrib/makefile/downloads/nsync/public // nsync头文件 静态库路径 tensorflow/tensorflow/contrib/makefile/gen/lib // TensorFlow静态库/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/lib // protobuf静态库/tensorflow/tensorflow/contrib/makefile/downloads/nsync/builds/default.macos.c++11 // nsync静态库 编译时需要这些静态库 libtensorflow-core.alibprotobuf.alibnsync.a其他: pthread m z CMake构建 git clone https://github.com/formath/tensorflow-predictor-cpp.gitcd tensorflow-predictor-cppmkdir build &amp;&amp; cd buildcmake ..make 构建完成后在bin路径下会看到一个simple_model可执行文件，运行./simple_model即可看到输出output value: 6。 需要注意的时，编译选项里一定要加这些-undefined dynamic_lookup -all_load，否则在编译和运行时会报错，原因可见dynamic_lookup和Error issues。 以上用c = a * b一个简单的网络来介绍整个流程，只要简单的修改即可应用到复杂模型中去，更复杂的一个例子可见src/deep_model.cc。 参考 tensorflow c++ prediction example Various Models implemented in TensorFlow Loading a TensorFlow graph with the C++ API Loading a tensorflow graph with the C++ API by using Mnist Tensorflow Different ways to Export and Run graph in C++ dynamic_lookup Error issues","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"广告CTR预估场景下的DNN调优实战","slug":"dnn_trick_for_ctr","date":"2021-09-06T10:32:05.000Z","updated":"2023-09-19T02:53:03.254Z","comments":true,"path":"2442aa9e/","permalink":"https://www.mathmach.com/2442aa9e/","excerpt":"","text":"特征 模型 性能 其他 参考 特征 DNN需要组合特征 LR模型的时候，我们需要构造许多组合特征，比如UserID与ItemID的组合，许多做DNN的都宣称简化了特征工程，由隐层学习特征交叉，但是隐层进行特征组合的方式并没有明确的理论解释，并且通过隐层参数学习的方式进行隐式的特征组合并不能保证收敛到最优解，通过显示的构造组合特征能给DNN提供一些先验信息，从实战来看，DNN加上显示的组合特征效果会好很多。 稀疏特征过滤 训练数据中出现频次过少的离散特征往往容易引起过拟合，需要统计频次并做过滤。效果比较好的一种方法是，比如生成day这一天的特征时，使用 [day-delta_day_num, day-1]之间的特征统计值来过滤day这一天的稀疏特征，相比使用[day-delta_day_num, day]之间的统计值，auc明显提升。delta_day_num可以设成14天，过滤阈值20，具体数据可以根据业务场景和实验效果来定。 DNN特征划分Group 和FFM类似，需要把特征划分成多个Group，每个Group里的特征做Embedding后Sum起来。划分方法，可以根据特征语义层面（用户、Item、组合）和数量、粒度进行划分。比如把用户相关特征划分成下面几个Group： 用户细粒度Id: UserId用户画像：Age，Gender，收入，职业用户行为：近期浏览的ItemIds 模型 每类特征设置不同Embedding Size 特征包含的信息越丰富，越需要更大的Embedding Size来描述，特征包含信息的丰富程度可以通过特征的粒度和数量表现出来，具体的一个划分方式可以看下图。 特征粒度方面，单特征相对算粗粒度，组合特征相对较细，组合的层次越深，粒度越细。比如UserId#ItemId的组合特征刻画了用户对商品的倾向，UserId#ItemId#Hour刻画了用户在某个时间对某个商品的倾向【比如外卖，举个例子，实际一般不会这么组合】。特征刻画的粒度越细，说明指代的越具体，包含的信息非常明确却单一，这类特征一般不需要再和其他特征进行组合，所以Embedding Size会更小。 特征数量方面，一般数量越大，包含的信息越多，比如UserId和ItemId可以达到上亿，一个UserId可以描述这个用户的很多信息，像Age和Gender这类特征规模很小的特征所包含的信息相对有限。 模型结构 Wide&amp;Deep最靠谱，DeepFM、DCN之类的效果都不大行。在Wide&amp;Deep模型的基础上，没有将Wide部分单独拿出来，而是和Deep在一起，通过特征划分Group后一起Embedding，效果可以超过Wide&amp;Deep，并且右边添加了一个基于离散特征统计的历史CTR的网络，可以降低模型的Variance，效果提升非常明显。总之，不要过分迷信一些灌水论文。 减少多余训练参数 二分类模型下，最后一层全连接的代码经常是下面这样： layer = ... # 倒数第二层weight = tf.get_variable('weight', [dim, 2], initializer=...)bias = tf.get_variable('bias', [2], initializer=...)logits = tf.matmul(layer, weight) + bias 因为是二分类，连接label=0的所有边其实不需要学习，0就是最优参数，如果加入学习的话，实际上多了一些冗余参数，而且梯度下降必定无法保障它们收敛到这个最优解。改成下面这样，auc可以较大提升。 layer = ... # 倒数第二层weight_positive = tf.get_variable('weight_positive', [dim, 1], initializer=...)bias_positive = tf.get_variable('bias_positive', [1], initializer=...)weight_neg = tf.get_variable('weight_negative', initializer=tf.constant(np.zeros((dim, 1), dtype=np.float32)), trainable=False)logits_positive = tf.matmul(layer, weight_positive) + bias_positivelogits_negative = tf.matmul(layer, weight_negative)logits = tf.concat([logits_negative, logits_positive], 1) 选一个好的基线模型 这些年DNN火起来后，大家都往DNN方向发展，很多团队宣称切换到了DNN，宣传文章写的也不错，但是从实际来看，真正把DNN用好的团队并不多。比如从GBDT切换到DNN的一些组，其实整个特征流程还是沿用的GBDT思路，用几百维连续特征来做DNN，或者简单加几个小规模离散特征，少数技术强悍的团队其实做的是百亿千亿特征、模型规模TGB级别的超大DNN，所以同样是Wide&amp;Deep模型，不同的规模下其实天壤之别。DNN相对于GBDT来说，是非常容易做出成果的，主要还是把GBDT作为基线模型有点太简单了，其实在搜索推荐这类个性化很强的场景下把GBDT换成百亿千亿级别特征的超大规模LR或者FFM也会获得很大提升，所以如果要做DNN的话，推荐用FFM来做基线，实战来看DNN相对FFM要做出成果并没有那么简单。 性能 大规模离散特征Embedding 稀疏特征的id做embedding时，由于TensorFlow内部使用一个shape=[id_num, embedding_size]的Variable做参数，需要把id映射成[0, id_num)间的一个数字。如果id量非常小的话，可以在特征提取后把id排序一遍生成从0开始的连续id值，但在工业界场景下id往往是用murmur hash生成的uint64 id，量级往往是百万到千亿级别，很难做排序。TensorFlow内部有一个Hash Table可以将uint64映射成从0开始的连续id，但可能将不同的id映射到embedding_variable的同一行，所以建议把embedding_variable的行数和num_oov_buckets设置的大一点，减小一点冲突。当然，最优方案应该是使用Map结构来实现Embedding Variable，现在官方并没有人做，我已经修改TensorFlow底层代码实现了一个，支持千亿离散特征的embedding，在公司内已经应用，这一块也可以参考阿里发布的TensorFlowRS。 embedding_variable = tf.get_variable('emb_var', [2*id_num+2, embedding_size], initializer=...)hash_table = tf.contrib.lookup.index_table_from_tensor(mapping=tf.constant([0]), num_oov_buckets=2*id_num, dtype=tf.int64)sparse_ids = hash_table.lookup(origin_sparse_ids)embedding = tf.nn.embedding_lookup_sparse(embedding_variable, sparse_ids, None, partition_strategy=\"mod\") Sparse Embedding性能 使用 def embedding_lookup_sparse_with_distributed_aggregation(params, sp_ids, sp_weights, partition_strategy=\"mod\", name=None, combiner=None, max_norm=None) 代替 def embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy=\"mod\", name=None, combiner=None, max_norm=None) 。后者在ps端lookup出许多embedding后传给worker，在worker端做聚合，前者在ps端做多个embedding的聚合后传给worker，通信量会小很多。 不要使用TensorFlow Feature Columns TensorFlow Feature Columns的性能很差，建议把特征相关的所有工作，包括离散化、组合等操作都放在单独的特征抽取工具里面，TensorFlow只包含模型部分代码。 QueueRunner批量读数据 使用read_up_to接口批量读数据，性能提升非常大。 reader = tf.TFRecordReader()_, serialized_example = reader.read(filename_queue)_, serialized_example = reader.read_up_to(filename_queue, 1000) 使用DataSet接口读数据 QueueRunner读数据时不能精确一轮一轮的读，很难做worker之间的barrier，TensorFlow DataSet可以实现精确读取一轮，在worker精确同步时比较有用TensorFlow实现Barrier。而且DataSet的性能和QueueRunner差不多，主要是几个接口的使用顺序要注意。 def _parse_function(examples_proto): features = {} features['label'] = tf.FixedLenFeature([], tf.float32) features['feature'] = ... instance = tf.parse_example(examples_proto, features) label = instance['label'] feature = instance['feature'] return label, featuredataset = tf.data.TFRecordDataset(file_name_list)dataset = dataset.prefetch(buffer_size=batch_size*100)dataset = dataset.shuffle(buffer_size=batch_size*10)dataset = dataset.batch(batch_size)dataset = dataset.map(_parse_function, num_parallel_calls=4)iterator = dataset.make_initializable_iterator() GPU vs CPU 现在很多做算法的言必GPU，其实很多场景下并不合适。CTR模型训练场景下，主要耗时操作是Embedding Lookup，不适合GPU，全连接层又很小，CPU足够应付。整体来看，P40比Intel® Xeon® Processor E5-2650 v4 (30M Cache, 2.20 GHz)快5%左右，但价格贵很多。2.7GHz的CPU性能可以提升30%，所以从性价比来看，推荐主频更快的CPU。这个一定要分应用场景，在场景下去做正确的决定，而不是人云亦云。 其他 训练千亿特征TGB级别参数的超大模型 将单机无法加载的超大模型做线上预测服务 秒级在线深度学习架构 参考 TensorFlow实现多Worker同步机制 TensorFlow Feature Columns","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"点击率预估","slug":"点击率预估","permalink":"https://www.mathmach.com/tags/%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"},{"name":"CTR","slug":"CTR","permalink":"https://www.mathmach.com/tags/CTR/"}],"author":"formath"},{"title":"分布式机器学习中的同步模式：ASP、BSP、SSP实验研究","slug":"sync_mode_experiment","date":"2020-03-15T12:36:39.000Z","updated":"2023-09-19T02:53:03.256Z","comments":true,"path":"c8ad6f19/","permalink":"https://www.mathmach.com/c8ad6f19/","excerpt":"","text":"背景 实验配置 效果 ASP模式 BSP模式 SSP模式(threshold=50) SSP模式(threshold=20) SSP模式(threshold=10) 分析 背景 之前在公司开发了一个Parameter Server架构的分布式机器学习系统，可以支持多种同步模式，支持异步的ASP、同步的BSP、半同步的SSP，但是在点击率预估等业务场景中，实际工作中最常用的还是ASP模式，其他两种模式并没有进行实验，这次想通过实验看下效果如何。 实验配置 使用[day-89, day]共90天的线上数据做训练，使用[day+1]一天的数据做验证 训练数据4亿左右，特征千万量级 集群：50 worker + 20 ps on Yarn, 8core,4g/node 点击率预估，模型使用最简单的LR 优化算法使用FTRL 不同实验只有同步方式不同，其他配置保持一样 效果 ASP模式 19:48:18 epoch: 1, train-logloss: 0.0627267, train-auc: 0.690643, valid-logloss: 0.0555645, valid-auc: 0.69878719:54:11 epoch: 2, train-logloss: 0.0622153, train-auc: 0.704938, valid-logloss: 0.0554252, valid-auc: 0.70261720:00:21 epoch: 3, train-logloss: 0.0620013, train-auc: 0.710765, valid-logloss: 0.0553471, valid-auc: 0.70491220:06:43 epoch: 4, train-logloss: 0.0618459, train-auc: 0.714920, valid-logloss: 0.0552953, valid-auc: 0.70635420:12:43 epoch: 5, train-logloss: 0.0617195, train-auc: 0.718254, valid-logloss: 0.0552550, valid-auc: 0.70750520:18:48 epoch: 6, train-logloss: 0.0616111, train-auc: 0.721076, valid-logloss: 0.0552250, valid-auc: 0.70835920:24:47 epoch: 7, train-logloss: 0.0615152, train-auc: 0.723545, valid-logloss: 0.0552006, valid-auc: 0.70906020:28:27 epoch: 8, train-logloss: 0.0614288, train-auc: 0.725751, valid-logloss: 0.0551802, valid-auc: 0.709684 BSP模式 19:55:23 epoch: 1, train-logloss: 0.0627236, train-auc: 0.690612, valid-logloss: 0.0555393, valid-auc: 0.69966520:06:58 epoch: 2, train-logloss: 0.0622139, train-auc: 0.704972, valid-logloss: 0.0554050, valid-auc: 0.70353020:20:43 epoch: 3, train-logloss: 0.0620007, train-auc: 0.710783, valid-logloss: 0.0553289, valid-auc: 0.70570020:29:27 epoch: 4, train-logloss: 0.0618450, train-auc: 0.714948, valid-logloss: 0.0552777, valid-auc: 0.70715520:39:05 epoch: 5, train-logloss: 0.0617186, train-auc: 0.718281, valid-logloss: 0.0552391, valid-auc: 0.70826420:48:00 epoch: 6, train-logloss: 0.0616103, train-auc: 0.721099, valid-logloss: 0.0552086, valid-auc: 0.70908720:57:18 epoch: 7, train-logloss: 0.0615145, train-auc: 0.723561, valid-logloss: 0.0551841, valid-auc: 0.70980421:09:38 epoch: 8, train-logloss: 0.0614279, train-auc: 0.725770, valid-logloss: 0.0551629, valid-auc: 0.710393 SSP模式(threshold=50) 20:00:14 epoch: 1, train-logloss: 0.0627070, train-auc: 0.690925, valid-logloss: 0.0555584, valid-auc: 0.69893720:08:23 epoch: 2, train-logloss: 0.0622105, train-auc: 0.705031, valid-logloss: 0.0554257, valid-auc: 0.70280120:19:17 epoch: 3, train-logloss: 0.0619988, train-auc: 0.710817, valid-logloss: 0.0553514, valid-auc: 0.70490220:27:04 epoch: 4, train-logloss: 0.0618438, train-auc: 0.714971, valid-logloss: 0.0553002, valid-auc: 0.70637520:38:13 epoch: 5, train-logloss: 0.0617177, train-auc: 0.718299, valid-logloss: 0.0552611, valid-auc: 0.70747620:48:29 epoch: 6, train-logloss: 0.0616096, train-auc: 0.721115, valid-logloss: 0.0552307, valid-auc: 0.70831521:00:22 epoch: 7, train-logloss: 0.0615140, train-auc: 0.723575, valid-logloss: 0.0552069, valid-auc: 0.70900421:18:24 epoch: 8, train-logloss: 0.0614276, train-auc: 0.725779, valid-logloss: 0.0551862, valid-auc: 0.709557 SSP模式(threshold=20) 20:38:15 epoch: 1, train-logloss: 0.0627076, train-auc: 0.690827, valid-logloss: 0.0555455, valid-auc: 0.69935220:46:12 epoch: 2, train-logloss: 0.0622098, train-auc: 0.705044, valid-logloss: 0.0554167, valid-auc: 0.70311720:55:21 epoch: 3, train-logloss: 0.0619982, train-auc: 0.710830, valid-logloss: 0.0553428, valid-auc: 0.70523721:06:25 epoch: 4, train-logloss: 0.0618434, train-auc: 0.714978, valid-logloss: 0.0552917, valid-auc: 0.70665121:20:52 epoch: 5, train-logloss: 0.0617175, train-auc: 0.718303, valid-logloss: 0.0552538, valid-auc: 0.70773021:32:35 epoch: 6, train-logloss: 0.0616095, train-auc: 0.721119, valid-logloss: 0.0552240, valid-auc: 0.70857521:45:32 epoch: 7, train-logloss: 0.0615138, train-auc: 0.723582, valid-logloss: 0.0552001, valid-auc: 0.70929021:56:57 epoch: 8, train-logloss: 0.0614273, train-auc: 0.725787, valid-logloss: 0.0551785, valid-auc: 0.709892 SSP模式(threshold=10) 21:21:47 epoch: 1, train-logloss: 0.0627156, train-auc: 0.690705, valid-logloss: 0.0555498, valid-auc: 0.69905521:32:30 epoch: 2, train-logloss: 0.0622118, train-auc: 0.705017, valid-logloss: 0.0554154, valid-auc: 0.70287821:44:33 epoch: 3, train-logloss: 0.0619991, train-auc: 0.710818, valid-logloss: 0.0553408, valid-auc: 0.70499621:54:42 epoch: 4, train-logloss: 0.0618440, train-auc: 0.714974, valid-logloss: 0.0552890, valid-auc: 0.70641522:03:06 epoch: 5, trainlogloss: 0.06171790, train-auc: 0.718299, valid-logloss: 0.0552505, valid-auc: 0.70756822:11:31 epoch: 6, train-logloss: 0.0616097, train-auc: 0.721113, valid-logloss: 0.0552197, valid-auc: 0.70843322:19:22 epoch: 7, train-logloss: 0.0615140, train-auc: 0.723578, valid-logloss: 0.0551951, valid-auc: 0.70911322:29:30 epoch: 8, train-logloss: 0.0614275, train-auc: 0.725781, valid-logloss: 0.0551743, valid-auc: 0.709645 分析 可以看出，BSP效果还是比ASP好一些，但差距非常小，只有万分位差距。当然，在不同数据上可能差距有所不同。另外，BSP每轮需要10分钟，ASP只需要6分钟。而且，这次实验还是在集群负载比较空闲的时候测的，由于机器学习和Spark、MapReduce等大数据任务共享集群，如果集群负载较高，可能慢节点的情况会更严重，BSP估计速度会更慢。所以结合效果和速度来说，并没有使用BSP模式的必要。 SSP模式，在阈值为50的情况下，效果基本就和ASP差不多了，但速度还是慢一些，和BSP的速度差不多，估计有个慢节点拖后腿了。随着阈值变小，SSP效果也在慢慢变好，和BSP的效果接近。每个配置只跑了一次，所以稍微有点波动。 另外，这个测试是在CTR预估模型上做的，是个非常稀疏的模型，在梯度更新时冲突的情况不太大，所以ASP效果和BSP并没有明显差别。在图像领域，都是稠密模型，All-Reduce是最常使用的梯度汇聚和参数更新方式，是类似BSP的完全同步模式。在稠密模型上ASP效果怎么样呢？后续有时间再试试。","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"点击率预估","slug":"点击率预估","permalink":"https://www.mathmach.com/tags/%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0/"},{"name":"CTR","slug":"CTR","permalink":"https://www.mathmach.com/tags/CTR/"}],"author":"formath"},{"title":"CMake管理第三方依赖","slug":"cmake_third_dependency","date":"2020-01-19T08:17:05.000Z","updated":"2023-09-19T02:53:03.254Z","comments":true,"path":"d183c0cd/","permalink":"https://www.mathmach.com/d183c0cd/","excerpt":"","text":"背景 FindPackageHandleStandardArgs 具体方案 回顾 背景 最近在一个C++项目中尝试Bazel编译，编译依赖方式确实写着比较舒服和直观，但最后链接出来的二进制文件在执行时报Segment error，但用CMake编译出来的二进制文件就可以成功执行，Bazel编译的问题无从下手。另外，Bazel无法从系统目录查找头文件，这就不能忍了，有人建议从cc_toolchain_config.bzl查找问题，但toolchain实在是有点麻烦，就暂时放弃Bazel，继续使用CMake了。Bazel里提供的git_repositry等从外部源自动下载编译依赖的方式很好用，所以就思考在CMake里是不是也有类似的东西呢。之前使用CMake时，第三方依赖都是手动先在本地安装好，后来查找到了CMake里提供了类似Bazel的命令，那就是ExternalProject，不过这个命令只管下载编译等操作，但git_repositry更好使一些，它可以根据依赖自动判断是不是下载，而ExternalProject就没这么丝滑了，所以本文记录下在CMake怎样基于ExternalProject打造git_repositry那种丝滑的体验。 FindPackageHandleStandardArgs 在具体方案之前，先看一下CMake里提供的这个函数，在后面的实现中它可是非常重要哦。 This module provides a function intended to be used in Find Modules implementing find_package(&lt;PackageName&gt;) calls. It handles the REQUIRED, QUIET and version-related arguments of find_package. It also sets the &lt;PackageName&gt;_FOUND variable. The package is considered found if all variables listed contain valid results, e.g. valid filepaths. 我们在CMake里查找包时使用find_package(&lt;PackageName&gt;)，它判断一个包是否找到就是利用了FindPackageHandleStandardArgs。这个函数会判断几个关键变量是否有正确的值，如果都经过了验证，就设置&lt;PackageName&gt;_FOUND，既找到了包，否则就没找到。它有两个函数定义，一个简单的是这样滴： find_package_handle_standard_args(&lt;PackageName&gt; (DEFAULT_MSG|&lt;custom-failure-message&gt;) &lt;required-var&gt;... ) 简单的例子， FIND_PACKAGE_HANDLE_STANDARD_ARGS(Gflags DEFAULT_MSG GFLAGS_INCLUDE_DIR GFLAGS_LIBRARY) 通过判断GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY是否有正确值来断定GFlags是否找到，这里的GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY当然是我们自己设定喽，比如我们这么设定它们，如果搜到了头文件和库文件，就设置正确路径，否则就没值嘛。注意，这里我们最好不要用GFLAGS_LIBIARIES这种变量，这种我们是用来作为链接依赖库的变量的呀，同理，头文件那个变量也一样哦。 find_path(GFLAGS_INCLUDE_DIR gflags/gflags.h /usr/local/include)find_library(GFLAGS_LIBRARY gflags HINTS /usr/local/lib) 具体方案 我们比较常用的一种第三方库依赖的方式是这样嘛，先在本地系统目录搜下，如果找到就用，如果找不到就自动去下载编译。所以这里我们还是以GFlags为例，分两步： * 从系统目录查找GFlags，如果找到则设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY * 如果上一步没找到，那么从某个地方下载Gflags，本地编译安装后，再设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY 我们把这两步定义成两个宏DO_FIND_GFLAGS_SYSTEM和DO_FIND_GFLAGS_DOWNLOAD，然后条件判断调用就行啦，像这样： if(NOT GFLAGS_FOUND) DO_FIND_GFLAGS_SYSTEM()endif()if(NOT GFLAGS_FOUND) DO_FIND_GFLAGS_DOWNLOAD()endif() DO_FIND_GFLAGS_SYSTEM比较简单哦，我们直接给出代码： macro(DO_FIND_GFLAGS_SYSTEM) find_path(GFLAGS_INCLUDE_DIR gflags/gflags.h PATHS /usr/local/include /usr/include ) message(\"GFLAGS_INCLUDE_DIR: \" ${GFLAGS_INCLUDE_DIR}) find_library(GFLAGS_LIBRARY NAMES gflags PATHS /usr/local/lib /usr/local/lib64 /usr/lib /usr/lib64 ) message(\"GFLAGS_LIBRARY: \" ${GFLAGS_LIBRARY}) FIND_PACKAGE_HANDLE_STANDARD_ARGS(Gflags DEFAULT_MSG GFLAGS_INCLUDE_DIR GFLAGS_LIBRARY ) set(GFLAGS_LIBRARIES ${GFLAGS_LIBRARY}) set(GFLAGS_INCLUDE_DIRS ${GFLAGS_INCLUDE_DIR}) mark_as_advanced(GFLAGS_LIBRARIES GFLAGS_INCLUDE_DIRS)endmacro() 先从系统目录查找头文件和库文件，如果找到就设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY，然后调用FIND_PACKAGE_HANDLE_STANDARD_ARGS来通过我们设置的两个变量来断定GFlags到底找没找到，如果找到它会自动设置GFLAGS_FOUND为True，那第二个宏，就是先下载再编译的那个，就不用执行喽。最后，我们设定GFLAGS_INCLUDE_DIRS和GFLAGS_LIBRARIES供我们的主程序作为头文件路径和库依赖路径使用呗。 第二个宏，我们终于用到开头提到的ExternalProject这个牛逼玩意了^_^ The ExternalProject_Add() function creates a custom target to drive download, update/patch, configure, build, install and test steps of an external project. 太多内容，咱就直接贴用法再讲解吧。 macro(DO_FIND_GFLAGS_DOWNLOAD) include(ExternalProject) ExternalProject_Add( Gflags URL https://github.com/gflags/gflags/archive/v2.2.1.zip URL_HASH SHA256=4e44b69e709c826734dbbbd5208f61888a2faf63f239d73d8ba0011b2dccc97a UPDATE_COMMAND \"\" CONFIGURE_COMMAND cmake -DCMAKE_INSTALL_PREFIX=${GFLAGS_ROOT_DIR} -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DGFLAGS_NAMESPACE=google . BUILD_COMMAND make BUILD_IN_SOURCE true INSTALL_COMMAND make install INSTALL_DIR ${GFLAGS_ROOT_DIR} ) ExternalProject_Get_Property(Gflags INSTALL_DIR) set(GFLAGS_INCLUDE_DIR ${INSTALL_DIR}/include) message(\"GFLAGS_INCLUDE_DIR: \" ${GFLAGS_INCLUDE_DIR}) set(GFLAGS_LIBRARY ${INSTALL_DIR}/lib/${LIBRARY_PREFIX}gflags${LIBRARY_SUFFIX}) message(\"GFLAGS_LIBRARY: \" ${GFLAGS_LIBRARY}) FIND_PACKAGE_HANDLE_STANDARD_ARGS(Gflags DEFAULT_MSG GFLAGS_INCLUDE_DIR GFLAGS_LIBRARY ) set(GFLAGS_LIBRARIES ${GFLAGS_LIBRARY}) set(GFLAGS_INCLUDE_DIRS ${GFLAGS_INCLUDE_DIR}) mark_as_advanced(GFLAGS_LIBRARIES GFLAGS_INCLUDE_DIRS)endmacro() ExternalProject_Add从gayhub上下载gflags源码，然后通过一系列编译安装操作，本地某临时目录就安装好GFlags了。里面几个参数CONFIGURE_COMMAND、BUILD_COMMAND、INSTALL_COMMAND都是项目常用的流程，还是比较舒服滴。安装好后，我们通过ExternalProject_Get_Property获取到真实安装路径，就可以像上面第一步那样设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY啦，后面都一样一样的。 回顾 是不是很简单？那咱总结下里面的关键点吧。 1. 先使用find_path、find_library查找系统头文件和库，找到了设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY变量 2. 本地没找到，就用ExternalProject_Add从某地下载安装，然后设置GFLAGS_INCLUDE_DIR和GFLAGS_LIBRARY变量 3. 使用FIND_PACKAGE_HANDLE_STANDARD_ARGS来验证上面两个变量，验证没问题则GFLAGS_FOUND为True 那主程序那边怎么用呢？上面那些东西都保存为third_party/FindGflags.cmake文件，在我们的CMakeLists.txt里把它导入就行啦。 # 导入FindGflags.cmakelist(APPEND CMAKE_MODULE_PATH ${CMAKE_SOURCE_DIR}/third_party)# 查找gflagsfind_package(Gflags)# 主程序头文件搜索路径include_directories( ${CMAKE_CURRENT_SOURCE_DIR} ${GFLAGS_INCLUDE_DIRS} )# 主目标add_executable(hello hello.cc)target_link_libraries( hello ${GFLAGS_LIBRARIES} ) 最后，几个常用的第三方库都用这种方式实现了下，主要是我自己用的哦。 https://github.com/formath/cmake_third_party","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"CMake","slug":"CMake","permalink":"https://www.mathmach.com/tags/CMake/"}],"author":"formath"},{"title":"SGD优化算法的各种变体","slug":"variants_of_sgd","date":"2019-08-15T07:45:05.000Z","updated":"2024-01-02T10:26:18.947Z","comments":true,"path":"f4f9dedd/","permalink":"https://www.mathmach.com/f4f9dedd/","excerpt":"","text":"背景 优化算法 SGD with Momentum Nesterov accelerated gradient SGD-L1(Cumulative) AdaGrad AdaDelta Adam AdamW FTRL FTML 参考文献 背景 2017年前，公司内部的算法团队还都是使用XGBoost来训练模型，手动构造的特征已经几百个，特征迭代效果微弱，但在搜索推荐场景下，有大规模的离散特征，这类特征记忆效果非常好，如果加入模型训练会获得不错的效果提升，但树模型并不适合大规模离散特征，所以我开发了一个基于Parameter Server架构的分布式机器学习框架，主要支持大规模离散的浅层模型，比如Logistic Regression、Factorization Machine、Field-aware Factorization Machine分类模型以及对应的回归模型和SVD分解。这个机器学习框架使用Yarn调度在公司的大数据集群上，在线上取得了非常不错的收益，框架后续又开始朝着深度模型和在线学习演化，目前公司算法团队已经基本往大规模离散DNN迁移完毕。这里主要记录一下训练框架支持的一些优化算法，公式脑子只能记个大概，还是写下来方便以后查阅。 窄的深度模型 -&gt; 宽的浅层模型 -&gt; 又宽又深的模型 -&gt; 秒级在线更新的又宽又深的模型 优化算法 SGD with Momentum Nesterov accelerated gradient SGD-L1(Cumulative) AdaGrad AdaDelta Adam AdamW FTRL FTML SGD with Momentum 超参数： 学习率 惯性项 更新公式： Nesterov accelerated gradient 超参数： 学习率 惯性项 更新公式： SGD-L1(Cumulative) 超参数： 学习率 学习率衰减 学习率衰减步长 L1正则化项 更新公式： AdaGrad 超参数： 学习率 更新公式： AdaDelta 超参数： 惯性项 更新公式： Adam 超参数： 学习率 惯性项 惯性项 衰减率 更新公式： AdamW 超参数： 学习率 惯性项 惯性项 衰减率 正则项 更新公式： FTRL 超参数： L1正则化项 L2正则化项 学习率控制 学习率控制 更新公式： FTML 超参数： 惯性项控制 惯性项控制 学习率 更新公式： 参考文献 Nesterov, Y. (1983). A method for unconstrained convex minimization problem with the rate of convergence o(1/k2). Doklady ANSSSR (translated as Soviet.Math.Docl.), vol. 269, pp. 543– 547. Qian, N. (1999). On the momentum term in gradient descent learning algorithms. Neural Networks : The Official Journal of the International Neural Network Society, 12(1), 145–151. Tsuruoka, Yoshimasa, Jun'ichi Tsujii, and Sophia Ananiadou. \"Stochastic gradient descent training for l1-regularized log-linear models with cumulative penalty.\" Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1. Association for Computational Linguistics, 2009. Duchi, John, Elad Hazan, and Yoram Singer. \"Adaptive subgradient methods for online learning and stochastic optimization.\" Journal of Machine Learning Research 12.Jul (2011): 2121-2159. Zeiler, Matthew D. \"ADADELTA: an adaptive learning rate method.\" arXiv preprint arXiv:1212.5701 (2012). Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014). Ilya Loshchilov, Frank Hutter. \"Decoupled Weight Decay Regularization.\" arXiv preprint arXiv:1711.05101 (2017). H. Brendan McMahan &amp; M Streter. Adaptive Bound Optimization for Online Convex Optimization. In COLT, 2010 H. Brendan McMahan. Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization. In AISTATS, 2011 H. Brendan McMahan, Gary Holt, D. Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie, Todd Phillips, Eugene Davydov, Daniel Golovin, Sharat Chikkerur, Dan Liu, Martin Wattenberg, Arnar Mar Hrafnkelsson, Tom Boulos, Jeremy Kubica, Ad Click Prediction: a View from the Trenches. In ACM SIGKDD, 2013 Shuai Zheng, James T. Kwok. Follow the Moving Leader in Deep Learning. The 34th International Conference on Machine Learning (ICML), Sydney, Australia, August 2017","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Numerical-Optimization","slug":"Numerical-Optimization","permalink":"https://www.mathmach.com/tags/Numerical-Optimization/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"}],"author":"formath"},{"title":"Hadoop平台上生成TensorFlow TFRecord的错误问题","slug":"tfrecord_on_hadoop","date":"2019-08-13T10:32:05.000Z","updated":"2023-09-19T02:53:03.257Z","comments":true,"path":"ca93562e/","permalink":"https://www.mathmach.com/ca93562e/","excerpt":"","text":"背景 解决方案 方案一 方案二 参考文档 背景 使用MapReduce on Yarn或者Spark on Yarn来生成TFRecord的过程中，会发生Hadoop和TensorFlow依赖的Protobuf版本不一致导致冲突的问题。 解决方案 方案一 在运行时不要指定胖jar包，通过libjars命令指定需要的protobuf版本。 export HADOOP_CLASSPATH=${LIB_PATH}/*hadoop jar your_tfrecord.jar \\ your_class \\ -Dmapreduce.job.user.classpath.first=true \\ -libjars ${LIB_PATH}/protobuf-java-3.3.1.jar,${LIB_PATH}/tensorflow-hadoop-1.0.jar 方案二 使用胖jar包，把需要用到的jar包中的类重命名，在程序中调用重命名后的类，避免和集群上低版本的jar包冲突。在pom.xml里添加下面的配置，com.google开头类换成third.com.google。 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/LICENSE&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;!-- 当protobuf、guava等冲突时，将com.google开头的类转换成third.com.google开头 --&gt; &lt;relocations&gt; &lt;relocation&gt; &lt;pattern&gt;com.google&lt;/pattern&gt; &lt;shadedPattern&gt;third.com.google&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;/relocations&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 参考文档 maven relocating class maven-shade-plugin入门指南","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"}],"author":"formath"},{"title":"VSCode下Markdown和LaTex混合编辑环境配置","slug":"macos_latex","date":"2019-01-14T09:48:05.000Z","updated":"2023-09-19T02:53:03.255Z","comments":true,"path":"ddd6f979/","permalink":"https://www.mathmach.com/ddd6f979/","excerpt":"","text":"背景 安装Tex环境 VSCode配置 中文字体支持 Markdown里使用LaTex 总结 背景 最近在公司用Markdown写技术博客时，需要插入伪代码块，而Markdown里没有找到比较美观的实现方案，想到之前在学校写论文时一直用LaTex，里面的伪代码非常漂亮，所以就想在Markdown里混合使用LaTex，下面是从网上找到的解决方案汇总，方便自己以后查阅。 安装Tex环境 从以下网址下载Tex环境后安装，这个是MacOS下的Tex，Windows系统的是别的。 http://www.tug.org/mactex/mactex-download.html VSCode配置 安装LaTeX Workshop插件 settings.json增加以下配置 \"latex-workshop.latex.recipes\": [ { \"name\": \"xelatex\", \"tools\": [ \"xelatex\" ] }, { \"name\": \"latexmk\", \"tools\": [ \"latexmk\" ] }, { \"name\": \"pdflatex -&gt; bibtex -&gt; pdflatex*2\", \"tools\": [ \"pdflatex\", \"bibtex\", \"pdflatex\", \"pdflatex\" ] } ], \"latex-workshop.latex.tools\": [ { \"name\": \"latexmk\", \"command\": \"latexmk\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"-pdf\", \"%DOC%\" ] }, { \"name\": \"xelatex\", \"command\": \"xelatex\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"%DOC%\" ] }, { \"name\": \"pdflatex\", \"command\": \"pdflatex\", \"args\": [ \"-synctex=1\", \"-interaction=nonstopmode\", \"-file-line-error\", \"%DOC%\" ] }, { \"name\": \"bibtex\", \"command\": \"bibtex\", \"args\": [ \"%DOCFILE%\" ] } ], \"latex-workshop.view.pdf.viewer\": \"tab\", \"latex-workshop.latex.clean.fileTypes\": [ \"*.aux\", \"*.bbl\", \"*.blg\", \"*.idx\", \"*.ind\", \"*.lof\", \"*.lot\", \"*.out\", \"*.toc\", \"*.acn\", \"*.acr\", \"*.alg\", \"*.glg\", \"*.glo\", \"*.gls\", \"*.ist\", \"*.fls\", \"*.log\", \"*.fdb_latexmk\" ], 中文字体支持 完成上面工作后，就可以在VSCode下编辑和预览Tex文件了。不过中文支持不好，需要按下面操作兼容中文字体。 * 打开~/.pandoc/templates/default.latex文件，把以下内容填进去。 \\documentclass[$if(fontsize)$$fontsize$,$endif$$if(lang)$$lang$,$endif$$if(papersize)$$papersize$,$endif$]{$documentclass$} \\usepackage{geometry} % 設定邊界 \\geometry{ top=1in, inner=1in, outer=1in, bottom=1in, headheight=3ex, headsep=2ex } \\usepackage[T1]{fontenc} \\usepackage{lmodern} \\usepackage{amssymb,amsmath} \\usepackage{ifxetex,ifluatex} \\usepackage{fixltx2e} % provides \\textsubscript % use upquote if available, for straight quotes in verbatim environments \\IfFileExists{upquote.sty}{\\usepackage{upquote}}{} \\ifnum 0\\ifxetex 1\\fi\\ifluatex 1\\fi=0 % if pdftex \\usepackage[utf8]{inputenc} $if(euro)$ \\usepackage{eurosym} $endif$ \\else % if luatex or xelatex \\usepackage{fontspec} % 允許設定字體 \\usepackage{xeCJK} % 分開設置中英文字型 \\setCJKmainfont{STSong} % 設定中文字型 \\setmainfont{Georgia} % 設定英文字型 \\setromanfont{Georgia} % 字型 \\setmonofont{Courier New} \\linespread{1.2}\\selectfont % 行距 \\XeTeXlinebreaklocale \"zh\" % 針對中文自動換行 \\XeTeXlinebreakskip = 0pt plus 1pt % 字與字之間加入0pt至1pt的間距，確保左右對整齊 \\parindent 0em % 段落縮進 \\setlength{\\parskip}{20pt} % 段落之間的距離 \\ifxetex \\usepackage{xltxtra,xunicode} \\fi \\defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase} \\newcommand{\\euro}{€} $if(mainfont)$ \\setmainfont{$mainfont$} $endif$ $if(sansfont)$ \\setsansfont{$sansfont$} $endif$ $if(monofont)$ \\setmonofont{$monofont$} $endif$ $if(mathfont)$ \\setmathfont{$mathfont$} $endif$ \\fi % use microtype if available \\IfFileExists{microtype.sty}{\\usepackage{microtype}}{} $if(geometry)$ \\usepackage[$for(geometry)$$geometry$$sep$,$endfor$]{geometry} $endif$ $if(natbib)$ \\usepackage{natbib} \\bibliographystyle{plainnat} $endif$ $if(biblatex)$ \\usepackage{biblatex} $if(biblio-files)$ \\bibliography{$biblio-files$} $endif$ $endif$ $if(listings)$ \\usepackage{listings} $endif$ $if(lhs)$ \\lstnewenvironment{code}{\\lstset{language=Haskell,basicstyle=\\small\\ttfamily}}{} $endif$ $if(highlighting-macros)$ $highlighting-macros$ $endif$ $if(verbatim-in-note)$ \\usepackage{fancyvrb} $endif$ $if(tables)$ \\usepackage{longtable} $endif$ $if(graphics)$ \\usepackage{graphicx} % We will generate all images so they have a width \\maxwidth. This means % that they will get their normal width if they fit onto the page, but % are scaled down if they would overflow the margins. \\makeatletter \\def\\maxwidth{\\ifdim\\Gin@nat@width&gt;\\linewidth\\linewidth \\else\\Gin@nat@width\\fi} \\makeatother \\let\\Oldincludegraphics\\includegraphics \\renewcommand{\\includegraphics}[1]{\\Oldincludegraphics[width=\\maxwidth]{#1}} $endif$ \\ifxetex \\usepackage[setpagesize=false, % page size defined by xetex unicode=false, % unicode breaks when used with xetex xetex]{hyperref} \\else \\usepackage[unicode=true]{hyperref} \\fi \\hypersetup{breaklinks=true, bookmarks=true, pdfauthor={$author-meta$}, pdftitle={$title-meta$}, colorlinks=true, urlcolor=$if(urlcolor)$$urlcolor$$else$blue$endif$, linkcolor=$if(linkcolor)$$linkcolor$$else$magenta$endif$, pdfborder={0 0 0}} \\urlstyle{same} % don't use monospace font for urls $if(links-as-notes)$ % Make links footnotes instead of hotlinks: \\renewcommand{\\href}[2]{#2\\footnote{\\url{#1}}} $endif$ $if(strikeout)$ \\usepackage[normalem]{ulem} % avoid problems with \\sout in headers with hyperref: \\pdfstringdefDisableCommands{\\renewcommand{\\sout}{}} $endif$ \\setlength{\\parindent}{0pt} %\\setlength{\\parskip}{6pt plus 2pt minus 1pt} \\setlength{\\emergencystretch}{3em} % prevent overfull lines \\title{\\huge 在OSX平台上的XeLaTeX中文測試} % 設置標題，使用巨大字體 \\author{FoolEgg.com} % 設置作者 \\date{February 2013} % 設置日期 \\usepackage{titling} \\setlength{\\droptitle}{-8em} % 將標題移動至頁面的上面 \\usepackage{fancyhdr} \\usepackage{lastpage} \\pagestyle{fancyplain} $if(numbersections)$ \\setcounter{secnumdepth}{5} $else$ \\setcounter{secnumdepth}{0} $endif$ $if(verbatim-in-note)$ \\VerbatimFootnotes % allows verbatim text in footnotes $endif$ $if(lang)$ \\ifxetex \\usepackage{polyglossia} \\setmainlanguage{$mainlang$} \\else \\usepackage[$lang$]{babel} \\fi $endif$ $for(header-includes)$ $header-includes$ $endfor$ $if(title)$ \\title{$title$} $endif$ \\author{$for(author)$$author$$sep$ \\and $endfor$} \\date{$date$} \\begin{document} $if(title)$ \\maketitle $endif$ $for(include-before)$ $include-before$ $endfor$ $if(toc)$ { \\hypersetup{linkcolor=black} \\setcounter{tocdepth}{$toc-depth$} \\tableofcontents } $endif$ $body$ $if(natbib)$ $if(biblio-files)$ $if(biblio-title)$ $if(book-class)$ \\renewcommand\\bibname{$biblio-title$} $else$ \\renewcommand\\refname{$biblio-title$} $endif$ $endif$ \\bibliography{$biblio-files$} $endif$ $endif$ $if(biblatex)$ \\printbibliography$if(biblio-title)$[title=$biblio-title$]$endif$ $endif$ $for(include-after)$ $include-after$ $endfor$ \\end{document} Markdown里使用LaTex Markdown文件里可以插入LaTex片段，可以通过Pacdoc将md文件转成pdf或其他文件。 新建一个md文件test.md，填入以下内容 ## 背景MacOS LaTex环境配置## 嵌入latex算法伪代码---header-includes: - \\usepackage[ruled,vlined,linesnumbered]{algorithm2e}---# Algorithm 1Just a sample algorithmn\\begin{algorithm}[H]\\DontPrintSemicolon\\SetAlgoLined\\KwResult{Write here the result}\\SetKwInOut{Input}{Input}\\SetKwInOut{Output}{Output}\\Input{Write here the input}\\Output{Write here the output}\\BlankLine\\While{While condition}{ instructions\\; \\eIf{condition}{ instructions1\\; instructions2\\; }{ instructions3\\; }}\\caption{While loop with If/Else condition}\\end{algorithm} md生成pdf pandoc --pdf-engine=xelatex test.md -o test.pdf 或者 pandoc --pdf-engine=xelatex --template=[template.latex的路径] test.md -o test.pdf 不配置--template时默认使用~/.pandoc/templates/default.latex。 总结 在VSCode里，如果Markdown文件里有LaTex片段的话，是无法完全预览的，所以只能用Pandoc转成pdf来看效果，如果你有更好的办法欢迎提供。","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Latex","slug":"Latex","permalink":"https://www.mathmach.com/tags/Latex/"},{"name":"Markdown","slug":"Markdown","permalink":"https://www.mathmach.com/tags/Markdown/"}],"author":"formath"},{"title":"安装GFlags和GLog的错误","slug":"install_gflags_glog","date":"2018-06-07T04:45:05.000Z","updated":"2023-09-19T02:53:03.255Z","comments":true,"path":"ee26f93c/","permalink":"https://www.mathmach.com/ee26f93c/","excerpt":"","text":"问题 安装 安装gflags 安装glog 参考 问题 在安装glog时可能会报错undefined reference to 'FlagRegisterer::FlagRegisterer'，原因及方案 GLog needs GFlags compiled in the \"google\" namespace instead of the now default \"gflags\" namespace.In order to set this namespace you must compile and install gflags from source and set the GFLAGS_NAMESPACE variable to \"google\". 安装 安装gflags git clone https://github.com/google/gflags.gitcd gflags &amp;&amp; git checkout tags/v2.2.1cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DGFLAGS_NAMESPACE=google .makemake install 安装glog git clone https://github.com/google/glog.gitcd glog &amp;&amp; git checkout tags/v0.3.5./autogen.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install 参考 configure-google-glog-and-gflags-for-c","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"GFlags","slug":"GFlags","permalink":"https://www.mathmach.com/tags/GFlags/"},{"name":"GLog","slug":"GLog","permalink":"https://www.mathmach.com/tags/GLog/"}],"author":"formath"},{"title":"MXNet之NNVM代码简析","slug":"nnvm","date":"2017-08-16T07:45:05.000Z","updated":"2023-09-19T02:53:03.255Z","comments":true,"path":"91c8dd96/","permalink":"https://www.mathmach.com/91c8dd96/","excerpt":"","text":"Op Symbol Graph IndexedGraph GraphExecutor InitFullGraph AssignContext InferShape&amp;InferType&amp;InferStorageType InitArguments FinishInitGraph InitDataEntryMemory InitCachedOps InitOpSegs Op class Op: 每个OP都有name和desc，还有argument和attr attr都保存在全局的OpManager里。 有同一个name的Op不一定是同一个Op，比如ElementWiseSum可能在不同的Node里会有不同数量的input，每个不同node里的Op都会生成一个Op实例，虽然这些Op名字一样，但attr不一样。不同的Op其实是用Op*或Op.index来区分，Op.index就是这个Op加入OpManager的序号 静态属性是在注册Op时确定的；动态属性（输入个数等）是在创建Node时由node的attr来确定的，创建时会调用op.parse(node.attr)。 Symbol Symbol里只有vector outputs DataEntry可以把Node串起来 Graph Symbol提供了许多图的接口，便于前端访问，而Graph里面没几个接口，主要就是有个indexed_graph，便于底层训练时快速访问。Symbol非常灵活，以后有可能支持动态图，但每次动态变化后都要先转成Graph，底层不太支持动态度，因为都是vector用index来索引node，不太适合中间插入一个node。 里面有vector outputs indexed_graph和attr 每个graph有以下attr： 网络结构的json string 每个NodeEntry的TShape的vector 每个NodeEntry的dtype的vector 每个NodeEntry的storage_id的vector 每个operator的device的vector 每个operator的device的unordered_map&lt;string, int&gt; IndexedGraph 里面一堆vector，把Graph里的node映射成vector的下标，方便快速访问。提供了一些类似Symbol里的接口，不过主要根据node的index来访问vector，而Symbol更像通过node组成的DAG来访问。 GraphExecutor InitFullGraph 做一件事，生成带backward的Graph，调用了nnvm::pass::Gradient copy_op，消除重复，比如c=a+b，dc/da和dc/db其实一样，只用一个NodeEntry表示就行了。 AssignContext 只做一件事，设置graph的两个属性：g.attr[\"context\"]和g.attr[\"device\"]，里面会调用nnvm::pass::PlaceDevice。 设置了in_arg、auc_arg和arg_grad的context，中间节点的context在哪里设置的？猜测可能在PlaceDevice里面 InferShape&amp;InferType&amp;InferStorageType 调用nnvm::pass::InferXXX推断，做的事情很类似，主要是设置g.attr[\"shape\"]、g.attr[\"dtype\"]、g.attr[\"storage_type\"]属性 InitArguments 使用用户提供的参数初始化g里面的数据，g.data_entry_、g.grad_store_等 有一个版本是带shared_buffer的 FinishInitGraph 设置g.attrs[\"dispatch_stypes\"]和g.attrs[\"storage\"]等属性 ###AttachOpExecs&amp;AttachOpResources 遍历g，为每个节点生成一个OpExecutor，设置g.attrs[\"op_execs\"]属性。 有三种类型Op：1）带状态的FStatefulCompute 2）backward节点，使用forward的State 3）普通节点FCompute InitDataEntryMemory 为data_entry_里的每个数据生成一个NDArray InitCachedOps 使用g.attrs[\"op_execs\"],初始化op_nodes_，里面的每个元素都是一个Engine可执行的Op，包括了use_vars_vars等 InitOpSegs 把上一步的op_nodes_分段隔成多个大的exec，每个大exec里其实有许多小exec，内部按序执行小exec，大exec的use_vars和mutute_vars是小exec的汇总，这样在engine里大exec作为一个执行单元","categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"}],"tags":[{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"},{"name":"MXNet","slug":"MXNet","permalink":"https://www.mathmach.com/tags/MXNet/"}],"author":"formath"},{"title":"联系博主","slug":"author","date":"2017-01-14T09:48:05.000Z","updated":"2023-09-19T02:53:03.254Z","comments":true,"path":"5c3de5e6/","permalink":"https://www.mathmach.com/5c3de5e6/","excerpt":"","text":"从事工作 毕业后一直从事搜索推荐广告方面的工作，负责过以下方面的工作，还算熟悉，欢迎沟通。 机器学习平台 基于PS的大规模离散机器学习系统（LR/FM/FFM/SVD） 分布式深度学习系统（千亿特征、支持秒级在线学习） 特征抽取系统 模型预估系统 机器学习应用 大规模CTR预估 大规模异构图Graph Embedding 相关性模型 自然语言理解 其他广告系统里常用的算法模型 搜索广告/推荐广告 触发策略（自然语言理解、向量召回、相关性模型、Bert、对比学习等） 模型预估（GBDT、LR、FFM、DNN等） 机制策略（smart bidding、ocpc等） 技术兴趣 除了本职工作外，对业界一些技术也比较感兴趣。 分布式系统 Yarn、Flink、Kubernetes等 以下开源项目Contributor TensorFlow DMLC(PS-Lite-CORE) Euler 编程 主要使用C++和Python，也经常用Java/Scala写些Spark/MR和业务代码。 生活爱好 足球、台球、乒乓球、看剧 联系 GitHub: https://github.com/formath WeChat: ForMath","categories":[{"name":"author","slug":"author","permalink":"https://www.mathmach.com/categories/author/"}],"tags":[],"author":"formath"}],"categories":[{"name":"tech","slug":"tech","permalink":"https://www.mathmach.com/categories/tech/"},{"name":"author","slug":"author","permalink":"https://www.mathmach.com/categories/author/"}],"tags":[{"name":"点击率预估","slug":"点击率预估","permalink":"https://www.mathmach.com/tags/%E7%82%B9%E5%87%BB%E7%8E%87%E9%A2%84%E4%BC%B0/"},{"name":"CTR","slug":"CTR","permalink":"https://www.mathmach.com/tags/CTR/"},{"name":"特征工程","slug":"特征工程","permalink":"https://www.mathmach.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"},{"name":"Feature-Engineering","slug":"Feature-Engineering","permalink":"https://www.mathmach.com/tags/Feature-Engineering/"},{"name":"Deep-Learning","slug":"Deep-Learning","permalink":"https://www.mathmach.com/tags/Deep-Learning/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://www.mathmach.com/tags/TensorFlow/"},{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://www.mathmach.com/tags/ChatGPT/"},{"name":"DeepSpeed","slug":"DeepSpeed","permalink":"https://www.mathmach.com/tags/DeepSpeed/"},{"name":"DeepSpeed-Chat","slug":"DeepSpeed-Chat","permalink":"https://www.mathmach.com/tags/DeepSpeed-Chat/"},{"name":"RLHF","slug":"RLHF","permalink":"https://www.mathmach.com/tags/RLHF/"},{"name":"PPO","slug":"PPO","permalink":"https://www.mathmach.com/tags/PPO/"},{"name":"Actor-Critic","slug":"Actor-Critic","permalink":"https://www.mathmach.com/tags/Actor-Critic/"},{"name":"强化学习","slug":"强化学习","permalink":"https://www.mathmach.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"},{"name":"搜索引擎","slug":"搜索引擎","permalink":"https://www.mathmach.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/"},{"name":"推荐系统","slug":"推荐系统","permalink":"https://www.mathmach.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"},{"name":"计算广告","slug":"计算广告","permalink":"https://www.mathmach.com/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/"},{"name":"Machine-Learning","slug":"Machine-Learning","permalink":"https://www.mathmach.com/tags/Machine-Learning/"},{"name":"Numerical-Optimization","slug":"Numerical-Optimization","permalink":"https://www.mathmach.com/tags/Numerical-Optimization/"},{"name":"CMake","slug":"CMake","permalink":"https://www.mathmach.com/tags/CMake/"},{"name":"Latex","slug":"Latex","permalink":"https://www.mathmach.com/tags/Latex/"},{"name":"Markdown","slug":"Markdown","permalink":"https://www.mathmach.com/tags/Markdown/"},{"name":"GFlags","slug":"GFlags","permalink":"https://www.mathmach.com/tags/GFlags/"},{"name":"GLog","slug":"GLog","permalink":"https://www.mathmach.com/tags/GLog/"},{"name":"MXNet","slug":"MXNet","permalink":"https://www.mathmach.com/tags/MXNet/"}]}